---
output:
  html_document:
    fig_height: 7
    fig_width: 10
  word_document: default
---
ERP model
=========


```{r setup,echo=FALSE,message=FALSE,warning=FALSE}
require(knitr)
require(reshape2)
require(data.table)
#library(scales)
require(ggplot2)
#library(data.table)
require(lme4)
#require(plyr)
#library(ggdendro)
require(stringr)
require(multcomp)  ## for multiple comparison stuff
require(emmeans)      ## for lsmeans()
options(contrasts = c("contr.treatment", "contr.poly"))
randomeff = ""
library(tidyverse)
library(signal)
library(kableExtra)
#library(buildmer)

print(sessionInfo())

set.seed(47)
options(knitr.table.format = "latex")
options(knitr.table.booktabs = TRUE)
opts_chunk$set(warning=FALSE, message=TRUE)

drawERP <- function(df,dv, iv2,iv3=NULL,iv4=NULL,iv5=NULL, iv1="depth", timesize=3, timeline.y=1, span = 0.8, xmax = 6, layerlabels=c("Stimulus", "NextWord", "Hidden"),facetrow=1){

  formstr = paste(dv," ~ ",iv1," + ",iv2)
  symlist = c(iv2)
  shapeiv= iv2
  if (!is.null(iv3)){
    formstr = paste(formstr," + ",iv3)
    shapeiv= iv3
    symlist = c(symlist,iv3)
  }
  if (!is.null(iv4)){
      formstr = paste(formstr," + ",iv4)
      symlist = c(symlist,iv4)
  }
  if (!is.null(iv5)){
      formstr = paste(formstr," + ",iv5)
      symlist = c(symlist,iv5)
  }
  mdf=aggregate(as.formula(formstr), df, mean)
   mdf$depth = 3 + mdf$depth

  stim = subset(mdf, depth == min(depth))
  early = stim
  early$depth = 1  # this keeps the lines from rising and separating at 0
  early[dv]=early[dv]/10  # this helps to simulate the time needed for the stimulus to be processed.
  stim$depth = 0
  stim[dv]=0
  mdf = rbind(stim,early,mdf)
#  mdf= mdf[order(mdf[[3]],mdf[[2]],mdf[[1]]),]
#  mdf[[1]] <- as.integer(mdf[[1]])
  mdf$dv = mdf[[dv]]
  mdf[[shapeiv]] = factor(mdf[[shapeiv]])
  mdf[[iv2]] = factor(mdf[[iv2]])
  mapping = aes_string(x=iv1, y="dv", linetype=iv2,colour = iv3, shape=shapeiv )
  newdepth = seq(min(mdf$depth), max(mdf$depth),length.out=100)
 # pchip(mdf$depth, mdf$abssum, newdepth)
  p1 = ggplot(mdf, mapping) +  geom_point(data=mdf[mdf$depth > 3,])
  p1 = p1 + geom_line(data = mdf %>% group_by(!!! syms(symlist))  %>%
              do({
                tibble(depth = seq(min(mdf$depth), max(mdf$depth),length.out=100),
                       dv = pchip(.$depth, .[[dv]], depth))
              }))
   p1 = p1 + xlab("Network layer")
  p1 = p1 +ylab("Sum Abs. Error")
  
  p1 = p1 + scale_x_continuous(breaks=c(0,4,6),labels=layerlabels) # 6,limits=c(0,6.5)
  p1 = p1 + scale_colour_grey()
  p1 = p1 + theme_bw() 
  p1 = p1 +theme(legend.background = element_rect(size=.4, color="grey80")) 
  p1=p1 + theme(legend.position="bottom")
  p1 = p1 + theme(panel.grid.major = element_blank(), 
                  panel.grid.minor = element_blank(),
                  panel.background = element_blank(), 
                  axis.line = element_line(colour = "black"))

  if (!is.null(iv4)){
    form = paste("~",iv4)
    if (!is.null(iv5)){
      form = paste(form,"+",iv5)
    }
    p1 = p1 + facet_wrap(as.formula(form) ,scales = "free",nrow=facetrow)
  }
 
  if (timesize != -1){
#    timeline.y=timeline.y+0.1
    p1 = p1 +   annotate("text", x = 4, y = timeline.y*1.05, label = "400ms", hjust = 1,size=timesize) 
    p1 = p1 +   annotate("text", x = 6, y = timeline.y*1.05, label = "600ms", hjust = 1,size=timesize) 
    p1 = p1 + annotate("segment",x=0.5, xend=xmax-0.5, y=timeline.y, yend=timeline.y, size = 0.5, arrow = arrow(length = unit(0.2, "cm")))
  }
  return(p1)
}
#p1 = drawERP(longnoraw, "value", "Condition","measure","variable",timesize=-1)
#p1 = p1 + facet_wrap( ~ measure+variable,scales = "free",nrow=1)
#p1
#wordccompinput$layer= factor(wordccompinput$layer)
#mapping = aes_string(x="depth", y=dependMeasure, colour = "Constraint",linetype="Expectation")
#drawERP(wordccompinput,dependMeasure,  "Constraint" ,"Expectation", timeline.y=2)
#drawERP(wordccompinput,dependMeasure,"Condition", span = 0.8, timeline.y=2.1)


computeClozeERPCorr <- function(df,dpm,layername){
  df2 = df[df$layer == "word" & df$measure == "output",]
  df2$word=as.character(df2$word)
  df2$word = str_replace(  df2$word, "^-","X.")

  df2$cloze = apply(df2,1,function(dff){ dff[which(dff["word"]==names(df2))] })
  df2$cloze = as.numeric(as.character(df2$cloze))
  erp = df[df$layer == layername & df$measure == "inputderiv",dpm ]

  print(paste("Correlation output prediction and ",dpm," error of ",layername," is ",cor(df2$cloze,erp),sep=""))
}
# computeClozeERPCorr(postverb.df,dependMeasure,"hidden")
# computeClozeERPCorr(cloze.df,dependMeasure,"word")

corrHiddenOutputInputDeriv <- function(df,dim1,dim2="",layername="hidden"){
  hiddf = subset(df,layer==layername & measure %in% c("output","inputderiv"))
  measnum= which(names(hiddf)=="measure")
  firstna = which(is.na(hiddf[1,measnum:length(hiddf)]))[1]-1
  if (is.na(firstna)){
    firstna = which(names(hiddf)=="depth")-1
  }
  hiddf = hiddf[,1:firstna]
  row.names(hiddf) <- 1:nrow(hiddf)
  lev = nlevels(factor(hiddf$Condition))
  hiddf = hiddf[1:(4 * 2 * lev),]
  print(xtabs(~ Condition, hiddf))
  outindf = melt(subset(hiddf,measure=="output"),id=1:measnum)
  names(outindf)[length(outindf)]="output"
  inputderdf = melt(subset(hiddf,measure=="inputderiv"),id=1:measnum)
  outindf$inputderiv =   inputderdf$value
 # outindf[outindf$output < 0.5 & outindf$output > 0.4,]
#  wordvarsame = subset(outindf,as.character(word)==as.character(variable))
#  print(paste("Correlation output and error of target word is ",cor(wordvarsame$output,wordvarsame$inputderiv)))
 # outindf = outindf[sample(length(outindf[[1]]),1000),]
  outindf[[dim1]] = factor(outindf[[dim1]])
  outindf$inputderiv = abs(outindf$inputderiv)
  smal = outindf$inputderiv < 0.5
 # outindf$inputderiv[smal] =outindf$inputderiv[smal] + 0.03*(as.numeric(outindf[smal,dim1])-2)
  
  p = ggplot(outindf, aes_string(x="output", y="inputderiv",shape=dim1))
#  p = p + stat_smooth(method="lm",se=F)
  if (dim2!=""){
    p = p + facet_wrap(as.formula(paste("~",dim2)))
  }
  p = p + geom_point(size=2) 
  p = p +  scale_shape_manual(values=c(20,3,4))
#  p = p + scale_colour_brewer( palette="Set1")
  p = p + scale_colour_grey()
  p = p + theme_bw() 
  p = p + ylim(0,1)
  p = p + xlim(0,1)
  p = p + ylab("Error derivative")
  p = p + xlab(paste("Activation of",layername," layer units"))
  p = p + theme(legend.position=c(0.85,.85),legend.background = element_rect(color="gray90"))
 # p = p + coord_flip()
  print(p)
}
#corrHiddenOutputInputDeriv(postverb.df,"Condition")
#myggsave("img/actderivtense.png",width=6,height=6)

#corrHiddenOutputInputDeriv(subset(cloze.df,sub=="s0"),"Condition",layername="word")
#myggsave("img/actderivcloze.png",width=6,height=6)

#corrHiddenOutputInputDeriv(cloze.df,"Condition",layername="word")
#corrHiddenOutputInputDeriv(postverb.df,"Agreement","Number")
#corrHiddenOutputInputDeriv(postverbcoul.df,"Probability","Agreement")
#```

#```{r}
                           
modelComparison <- function(model,modellist=list(),verbose=0,filename=""){
  #  print(model)
  terms = attr(terms(model),"term.labels")
  modellist = append(modellist,model)
  #  print(terms)
  if (length(terms) > 0){
    newformula = paste(". ~ . - ",terms[length(terms)],"")
    print(paste("remove",newformula))
    model2 = update(model, as.formula(newformula))
    if (verbose > 0){
      print(summary(model2))
    }
    am1=anova(model2, model)
    print(am1)
    sig = ifelse(am1$`Pr(>Chisq)`[2]<0.05," *** ","")
    print(paste("########## Above comparison for ",terms[length(terms)],sig))
    
    terms = attr(terms(model),"term.labels")
    modellist = modelComparison(model2,modellist)
  }
  if (str_detect(filename,"rds")){
    saveRDS(modellist,file=filename)
  }
#  save(modellist, file= filename)
  return(modellist)
}

getModelNumHighestTerm <- function(varname,modellist) {
  for (i in 1:length(modellist)) {
    terms = attr(terms(modellist[[i]]), "term.labels")
    
    if (length(terms) > 0 & terms[length(terms)] == varname) {
      return(i)
    }
  }
  return(-1)
}

## roundNonZero
printInteraction <- function(ph){
  txt = ""
  lastest=NULL
  for (mi in 1:length(ph)){
    m=ph[mi]
    mname = names(m)
    mtest = m[[1]]$test
#    print(m[[1]]$test)
    
    intdf = data.frame(pval = round(mtest$pvalues,4),est = abs(round(mtest$coefficients,4)))
    intdf$tstat = abs(round(mtest$tstat,2))
    intdf$df = m[[1]]$df
    intdf$pvalstr = format.pval(pv = intdf$pval, digits = 2,eps=0.001,nsmall = 3)
    intdf$pvalstr = ifelse(substr(intdf$pvalstr,1,1)!='<',paste("=",intdf$pval,sep=""),intdf$pvalstr)
    intdf$wordstr = paste("@@Posthoc: There was a significant difference for ",row.names(intdf),", diff = ",intdf$est,", t(",intdf$df,")=",intdf$tstat,", p",intdf$pvalstr,sep="")
    
    intdf$wordstr = ifelse(intdf$pval > 0.05,paste("@@Posthoc: There was no difference for ",row.names(intdf),", p=",intdf$pval,sep=""), intdf$wordstr )
    
    txt = paste(txt,"\nPosthoc tests for ",mname,"\n",paste(intdf$wordstr,collapse="\n"))
    txt = str_replace_all(txt,"p<","p$<$")
    if (!is.null(lastest)){
      estlast = round(intdf$est/lastest,3)
      lastest = round(lastest/intdf$est,3)
      ratiotxt = paste("\nratio ",row.names(intdf)," ",estlast," rev ",lastest,collapse=",",sep=" ")
      txt = paste(txt,ratiotxt)
    }
    
    lastest = intdf$est
  }
  return(txt)
}
# cat(printInteraction(posthocs))

modellist = list()

reportChisqur <- function(outstr,model.anova){
  chisqr = round(model.anova$Chisq[2],2)
  chisqrdf = model.anova$"Chi Df"[2]
  chisqrp = model.anova$"Pr(>Chisq)"[2]
  
  chisqrpf = format.pval(pv = chisqrp, digits = 2,eps=0.001,nsmall = 3)
  if (substr(chisqrpf,1,1)!='<'){
    chisqrpf = paste("=",chisqrpf,sep="")
  }else{
    chisqrpf = str_replace(chisqrpf,"^<","$<$")
  }
#  outstr = paste(c("beta","SE","z","p"),oneline,collapse=", ",sep="=")
  if (outstr != ""){
    outstr=paste(outstr,", ",sep="")
  }
  outstr = paste(outstr,"$\\chi^2$(",chisqrdf,")=",chisqr,", p",chisqrpf,sep="")
  return(list(outstr,chisqrp))
}

roundNonZero <- function(val){
  tval = val
  pow = 1;
  repeat {
    if (abs(tval) > 1){
      return(round(val,pow))
    }
    tval = tval * 10
    if (pow == 7){
      return(round(val,pow))
    }
#    print(tval)
#    print(pow)
    pow = pow + 1
  }
  return(val)
}

report <- function(varname, modellist){
  if (length(modellist) < 1){ return(list("NOMODEL",0.1)) }
  
  fullmodel=modellist[[1]]
  model.sum = summary(fullmodel)
  model.coef = coefficients(model.sum)
  outstr=""
  if (varname %in% rownames(model.coef)){
    oneline = model.coef[varname,]
    beta = roundNonZero(oneline[[1]])
    se = roundNonZero(oneline[[2]])
    outstr = paste("$\\beta$=",beta,", SE=",se,sep="")
  }else{ return(list("NORESULTS",0.1)) }
  
  tm = getModelNumHighestTerm(varname,modellist)
  model.anova = anova(modellist[[tm]],modellist[[tm+1]])
  return(reportChisqur(outstr,model.anova))
}

printMixedModelResults<- function(modellist,dm=""){
  if (dm == ""){dm = dependMeasure}
  if (length(modellist) < 1){ return(c("NOMODEL"))}
  outputlist = c("\n\nMixed Model Results")
  model = modellist[[1]]
  terms = attr(terms(model),"term.labels")
  last = terms[length(terms)]
  for (t in terms){
    extra = ""
    if (t == last){
       extra = "@@"
    }
    art ="a"
    type = "main effect"
    if (str_detect(t,":")){
      art = "an"
      type = "interaction"
    }
      col = str_split(t,":")[[1]]
#      pred = model@frame[,col]
      meandf = aggregate(as.formula(paste(dm," ~ ",paste(col,collapse=" + "),sep="")), model@frame,mean)
      meandf[,dm]=round(meandf[,dm],4)
#      for (i in 1:length(meandf)){
#        cn = names(meandf)[i]
#        meandf[,cn] = paste(cn,meandf[,cn],sep="=")
#      }
#      meandf$all = apply(meandf,1, paste,collapse=" ")
#      meanstr = paste(meandf$all,collapse="; ")
      mlist = capture.output(meandf)
    meanstr = paste(mlist,collapse ="\n")
        
    g = report(t,modellist)
    if (g[[2]] > 0.05){
      art = "no"
    }
    txt = paste(extra,"",art," ",type," of ",t," ,",g[[1]]," ",sep="")
    outputlist = append(outputlist,txt)
#    outputlist = append(outputlist,meanstr)

  }
  return(outputlist)
}
# cat(paste(printMixedModelResults(modellist),collapse="\n"))

# shows words activations and errors
showWordOutError <- function(words,vars,df){
  worddf = subset(df, layer == "word") 
  form = paste("cbind(",words,") ~ ",paste(vars,collapse=" + "),sep="")

  first = which(names(worddf)=="none")
  end = length(worddf)
#  worddf[,first:end] = abs(worddf[,first:end])

  meanbyword = aggregate(as.formula(form),worddf, mean)
  meanbywordlong= melt(meanbyword,id.var=1:length(vars))
  p1 = ggplot(meanbywordlong, aes_string(x=vars[1], y="value", fill = "variable")) 
  p1 = p1 + geom_bar(stat="identity",position="dodge") 
  if (length(vars) < 3){
  p1 = p1 + facet_wrap(as.formula(paste("~",vars[2])),scales = "free",nrow=1)
  }else{
   if (length(vars) < 4){
    p1 = p1 + facet_wrap(as.formula(paste("~",vars[2]," + ",vars[3])),scales = "free")
#    p1 = p1 + facet_grid(as.formula(paste(vars[3],"~",vars[2])),scales = "free")
   }else{
    p1 = p1 + facet_wrap(as.formula(paste("~",vars[2]," + ",vars[3]," + ",vars[4])),scales = "free")
   }
#      p1 = p1 + facet_wrap(~ vars[1],scales = "free",nrow=1)
  }
  p1 = p1 + theme(legend.position="bottom")
  return(p1)
}
#showWordOutError("the,X.ss,X.ing,X.ed,X.par",c("Condition","measure"),postverbcoul.df)

computeN4P6correlation <- function(df){
  dfword = subset(df,layer == "word")
  depmcol = which(names(dfword)==dependMeasure)
  names(dfword)[depmcol]=paste(dependMeasure,"word",sep="")
  dfword$abssumhid = subset(df,layer == "hidden")[,depmcol]
  dfword$abssumword=dfword$abssumword*-1
  return(cor(dfword$abssumhid,dfword$abssumword))
}
#computeN4P6correlation(wordccompinput)

computeN4P6correlation2 <- function(df,gram,ungram,cond="Condition"){
  df2 = subset(df, measure == "inputderiv")
  oneset = df2[df2[cond]==gram,]
  oneset$viol = df2[df2[cond]==ungram,"abssum"] 
  oneset$N4 = oneset$viol - oneset$abssum

  #meandf2=aggregate(abssum ~ layer + Condition + sub, df2, mean)
  
  twolayers = subset(oneset,layer == "word")
  twolayers$P6 = subset(oneset,layer == "hidden")$N4
  twolayers$N4 = twolayers$N4 * -1
  return(cor(twolayers$N4,twolayers$P6))
}
# computeN4P6correlation2(postverb.df,"Control","Violation")
#corrHiddenOutputInputDeriv(postverb.df,"Condition")

removeNAColumns = function(df){
  return(df[,colSums(is.na(df))<nrow(df)])
}


removeWords<-function(df){
    onlyerpdf = subset(df,! measure %in% layerNotERP)
  end = which(names(onlyerpdf)=="depth")-1
  first = which(names(onlyerpdf)=="none")
  nounitsonlyerpdf = onlyerpdf[,-(first:end)]
  return(nounitsonlyerpdf)
}

removeWordsDrawERP <- function(df,dv, iv2,iv3=NULL,iv4=NULL,iv5=NULL, iv1="depth", extra="", showFig=FALSE){
  onlyerpdf = subset(df,! measure %in% layerNotERP)
  end = which(names(onlyerpdf)=="depth")-1
  first = which(names(onlyerpdf)=="none")
  nounitsonlyerpdf = onlyerpdf[,-(first:end)]
  dvlen = length(names(nounitsonlyerpdf))- which(names(nounitsonlyerpdf)=="depth")
  longnoraw= melt(nounitsonlyerpdf,id.var=1:(length(nounitsonlyerpdf)-dvlen))
  
  print(head(longnoraw))
  p1= drawERP(longnoraw,dv,iv2,iv3,iv4,iv5,iv1, timesize=-1)
  if(showFig){
    print(p1)
  }
  return(nounitsonlyerpdf)
}
#norawpostverbnotargout.df=removeWordsDrawERP(postverb.df,"value","Agreement","Number","measure",iv5="variable",showFig=T)
#norawpostverbnotargout.df=removeWordsDrawERP(postverb2.df,"value","Condition","epoch",showFig=FALSE)

#romrawpostverbnotargout.df=removeWordsDrawERP(romFinalNtest,mapping)
#romNotrawpostverbnotargout.df=removeWordsDrawERP(romNotFinalNtest,"value","Condition","measure","variable",showFig=FALSE)
myggsave <- function(fname, width=6, height=6){
#  ggsave("img/actderivcloze.png",width=6,height=6)
  fname = str_replace(fname,".png",".pdf")
  ggsave(fname, height=height, width=width, units='in')
  part1 = "convert -density 600x600"
  part2 = "-quality 90 -alpha remove"
  epsfname = str_replace(fname,".pdf",".eps")
  system(paste(part1,fname,part2,epsfname)) 
#  system(paste("rm -f ",fname))
#brain1.pdf -quality 90 -alpha remove brain1test.eps")
}
```





```{r}
noslopes=TRUE   # set to use just random intercept model
noslopes=FALSE  # set to false to get maximal model

if (!file.exists("results/resultdata.rds")){
  write("reading dataframe.csv", stderr())
  # load data for all models
#  resultWhole.df <- read.csv("smalldevel.csv") 
  resultWhole.df <- read.csv("results/dataframe.csv") # automatically uses working dir
  write("finished reading dataframe.csv", stderr())
  result.df <- resultWhole.df[,0:97]
#  result.df <- removeNAColumns(resultWhole.df)
  names(result.df)[6]<-"Condition"
  
   result.df$file=as.character(result.df$file)
  result.df$sub = str_extract(result.df$file,"[-]s[0-9]+[-]")
  result.df$sub = str_replace_all(result.df$sub,"[-]","")
  result.df$sub=factor(result.df$sub)
  
  result.df$epoch = as.integer(str_extract(result.df$file,"[0-9]+$"))
  result.df$coul = str_extract(result.df$file,"[0-9.]+vcoul[12]")
  result.df$vrom = str_extract(result.df$file,"[0-9.]+vrommer")
  result.df$vromNot = str_extract(result.df$file,"[0-9.]+vromNot")
  result.df$devellearn = str_extract(result.df$file,"[0-9.]+violation")
 
#  result.df$file = NULL
  epochCol = which(names(result.df)=="epoch")
  subCol = which(names(result.df)=="sub")
  coulCol = which(names(result.df)=="coul")
  vromCol = which(names(result.df)=="vrom")
  vromNotCol = which(names(result.df)=="vromNot")
  devellearnCol = which(names(result.df)=="devellearn")
  
  result2.df = result.df[,c(subCol,coulCol,vromCol,vromNotCol,devellearnCol,epochCol,0:(subCol-1))]
  names(result2.df)[which(names(result2.df)=="sent")]<-"Example"
  
  result2.df$tick = result2.df$tick+1
  result2.df$layer = factor(result2.df$layer, levels=c("word","compress", "hidden","cword"))
  result2.df$depth = as.numeric(result2.df$layer)
  result.df=result2.df
#  saveRDS(result.df,file="smalldevel.rds")
  saveRDS(result.df,file="results/resultdata.rds")
}else{
  print("using Rds file")
#  devresult.df=readRDS(file="smalldevel.rds")
  result.df=readRDS(file="results/resultdata.rds")
}

#print folder list to make sure correct folders 
folder = str_replace(result.df$file[1],"/derivatives.*","")
if (folder == "derivatives100000"){
  folder = basename(getwd())
}
sublist = paste(levels(result.df$sub),collapse=",")
print(paste("Folder",folder," nsub=",sublist))

# load counts
counts.df = read.csv("results/counts.csv")
counts.df$perc = round(100*counts.df$prop)
#print(counts.df[order(counts.df$pair),])
unigram.df = read.csv("results/unigram.csv")
#print(unigram.df[unigram.df$pair%in%c("wine","water","tea","cake"),])

result2.df=result.df 
first=which(names(result2.df)=="the")-1
end=which(names(result2.df)=="per")
# compute metrics Hidden layer is smaller than Lexical layer, so this captures all units
# hidden has only 50 units, so rest are marked with NA
result2.df$abssum  = rowSums(abs(result2.df[,first:end]),na.rm = TRUE)  # sum abs error
result2.df$absmean  = rowMeans(abs(result2.df[,first:end]),na.rm = TRUE) # mean abs error

#object.size(result2.df[,first:end])
#Sys.getenv("R_MAX_VSIZE")


couldf = subset(result2.df,epoch == max(result2.df$epoch) & !layer %in% c("cword") & !is.na(coul))
couldf$file = NULL
couldf$vrom = NULL
couldf$vromNot = NULL
#xtabs(~ Condition + coul, couldf)
print(unique(couldf$coul))

rommerdf = subset(result2.df,epoch == max(result2.df$epoch) & !layer %in% c("cword") & !is.na(vrom))
rommerdf$file = NULL
rommerdf$coul = NULL
rommerdf$vromNot = NULL

rommerNotdf = subset(result2.df,epoch == max(result2.df$epoch) & !layer %in% c("cword") & !is.na(vromNot))
rommerNotdf$file = NULL
rommerNotdf$coul = NULL
rommerNotdf$vrom = NULL

develop.df =  subset(result2.df,!layer %in% c("cword") & is.na(coul) & is.na(vrom) & is.na(vromNot))
develop.df$file = NULL
develop.df$coul = NULL
develop.df$vrom = NULL
develop.df$vromNot = NULL
develop.df$devellearn = NULL

adultdata.df = subset(develop.df,epoch == max(develop.df$epoch) )
adultdata.df$file = NULL
adultdata.df$vrom = NULL
adultdata.df$coul = NULL
adultdata.df$vromNot = NULL
adultdata.df$devellearn = NULL


#load("adultdata.RData")
layerNotERP = c("output","target", "error","myoutputder","myinputder")
dependMeasure = "abssum" # we can change the dependent measure for all models
mainMeasure = "inputderiv"
p600layer = "hidden"
#load(adultdata.df)
first=which(names(adultdata.df)=="the")
end=which(names(adultdata.df)=="per")
# when doing final version, change noslopes to FALSE
figwidth=6
figheight=3

```


-------------------

## Cloze

```{r, message=FALSE, fig.width=12, fig.height=4}
write("cloze", stderr())
cloze.df = subset(adultdata.df,  str_detect(adultdata.df$Condition,"CLOZE") & wordcat %in% c('NOUNI'))
cloze.df$Condition = factor(cloze.df$Condition,labels=c("High Cloze","Medium Cloze","Low Cloze"))

print(head(cloze.df[cloze.df$measure=="target",c("word","wordcat","Condition","Example","tick")])) # check

# check that layers are the right size
cloze.df$laylen = 1+(end-first)-rowSums(apply(cloze.df[,first:end],2,is.na))
print(aggregate(laylen ~ layer + measure, cloze.df,mean))
cloze.df$laylen=NULL

showWordOutError("coffee,tea,wine,water,cake",c("Condition","measure"),cloze.df)
```


```{r,fig.height=6,fig.width=6}
computeClozeERPCorr(cloze.df,dependMeasure,"word")
computeClozeERPCorr(cloze.df,dependMeasure,"hidden")

corrHiddenOutputInputDeriv(cloze.df,"Condition",layername="word")
myggsave("img/actderivcloze.png",width=6,height=6)
```

```{r,fig.height=4,fig.width=12,warning=F}
# this is for creating ERP figure
nooutput = subset(cloze.df, ! measure %in% layerNotERP )
end = which(names(nooutput)=="depth")-1
first = which(names(nooutput)=="none")
norawcloze.df = nooutput[,-(first:end)] # remove word specific activations/error


dvlen = length(names(norawcloze.df))- which(names(norawcloze.df)=="depth")
longnoraw= melt(norawcloze.df,id.var=1:(length(norawcloze.df)-dvlen)) # make long format
print(folder) # we use folder rename html file
# add target layer for figure
#mapping = aes(x=depth, y=value, colour = Condition,linetype=Condition)
p1 = drawERP(longnoraw,"value",  "Condition" ,"measure","variable" ,timesize=-1)
#p1= drawERP(longnoraw,mapping, timesize=-1,span = 0.8)
p1 = p1 + facet_wrap( ~ measure+variable,scales = "free",nrow=1)
p1

print(folder)
```

```{r,fig.height=3,fig.width=6}
# this is the counts for verb arguments in the input
interactionText="NO TEXT"


# get example for table
tablesub = subset(norawcloze.df,layer == "word" & measure == mainMeasure)
exampleTable = tablesub[1:3,c("Condition","Example")]
tabletext = kable(exampleTable,format="latex",row.names=FALSE)
print(exampleTable)

wordccompinput  = subset(norawcloze.df,measure == mainMeasure & layer %in% c("word",p600layer) )

if (nlevels(adultdata.df$sub) > 4){ # do mixed with more than 9 subj
  print("run models")
  # our analysis uses this set

  wordccompinput$cloze = 0
  wordccompinput$cloze[wordccompinput$Condition=="Low Cloze" ]=1
  wordccompinput$cloze[wordccompinput$Condition=="High Cloze" ]=-1
  wordccompinput$cword = ifelse(wordccompinput$layer=="word",0.5,-0.5)

  # this is the main mixed model with centered variables
  randomeff = " + (1 + cloze*cword |sub)"
  if (noslopes){ randomeff = " + (1 | sub)" }
  formu = as.formula(paste(dependMeasure,"~ cloze*cword",randomeff ))
  omnimodel = lmer(formu, wordccompinput,control=lmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=50000)))
  print(summary(omnimodel))
  
  modellist = modelComparison(omnimodel) # create anova table by terms subtraction

}
# create figure for paper
#mapping = aes_string(x="depth", y=dependMeasure, colour = "Condition",linetype="Condition")
drawERP(wordccompinput,dependMeasure,"Condition", span = 0.8, timeline.y=2.1)
if (!noslopes){ # when doing final version, change noslopes to FALSE
  myggsave("img/cloze.png",width=figwidth,height=figheight) # control font size with height/width
}

n4P6cor = computeN4P6correlation(wordccompinput)
print(paste("N400/P600 correlation",n4P6cor))
n4P6cor = computeN4P6correlation2(wordccompinput,"High Cloze","Low Cloze")
print(paste("N400/P600 correlation",n4P6cor))

```

CUT AND PASTE INTO LATEX DOC
click in box and use right arrow to see whole text

```latex
Cloze probabilities were manipulated in the language input on direct objects in active transitive items.
The same test word \textit{water} was used in each of the test sentences, but its cloze probability for each verb was manipulated.  The same test word \textit{water} was used in each of the test sentences, but its cloze probability for each verb was manipulated.  It occurred `r counts.df$perc[counts.df$pair=="drink water"]`\% of the time with the verb \textit{drink} (High Cloze), `r counts.df$perc[counts.df$pair=="taste water"]`\% with the verb \textit{taste} (Medium Cloze), and `r counts.df$perc[counts.df$pair=="take water"]`\% of the time with the verb \textit{take} (Low Cloze).

This is an example of the stimuli used in the model
```{r,echo=FALSE,results="asis",warning=FALSE,message=FALSE}
#print(paste(tabletext,sep="",collapse="\n"))
cat(paste(tabletext))
cat(paste("\nThe maximal model for the data had random slopes",randomeff))
cat(paste(printMixedModelResults(modellist),collapse="\n"))
```

```


-------------------

## Federmeier et al. 2007

```{r n400-line, message=FALSE, fig.width=12, fig.height=8}
write("feder", stderr())
feder.df = subset(adultdata.df,  str_detect(adultdata.df$Condition,"(EXPECT)") & wordcat %in% c('NOUNI'))
cond = str_split_fixed(feder.df$Condition,";",2)
feder.df$Constraint = cond[,1]
feder.df$Expectation = cond[,2]
feder.df$Constraint = factor(feder.df$Constraint,labels=c("Strong","Weak"))
feder.df$Expectation = factor(feder.df$Expectation,labels=c("Expected","Unexpected"))
nc = length(feder.df)
feder.df = feder.df[,c(nc-1,nc,1:(nc-2))] # move new columns to front

print(head(feder.df[feder.df$measure=="target",c("word","wordcat","Condition","Example","tick")])) # check

showWordOutError("coffee,tea,wine,water,cake",c("Expectation","Constraint","measure"),feder.df)
```

```{r,fig.height=4,fig.width=12}
computeClozeERPCorr(feder.df,dependMeasure,"word")

corrHiddenOutputInputDeriv(feder.df,"Expectation",dim2="Constraint",layername="word")
```


```{r,fig.height=4,fig.width=12}
# this is for creating ERP figure
nooutput = subset(feder.df, ! measure %in% layerNotERP )
end = which(names(nooutput)=="depth")-1
first = which(names(nooutput)=="none")
norawfeder.df = nooutput[,-(first:end)] # remove word specific activations/error

catmembers = str_split("coffee,tea,wine,water,beer",",")[[1]]
nooutput$abssumcat  = rowSums(abs(nooutput[,catmembers]),na.rm = TRUE)  
nooutput$abstarget <- abs(nooutput[,"tea"])
norawclozecat.df = nooutput[,-(first:end)] 
wordccompinputcat  = subset(norawclozecat.df,measure == mainMeasure & layer %in% c("word") )
wordccompinputcat$abssumcatnotar = wordccompinputcat$abssumcat - wordccompinputcat$abstarget
wordccompinputcat$abssumcatnotarprop = wordccompinputcat$abssumcatnotar/wordccompinputcat$abssum
wordccompinputcat$abstargetprop = wordccompinputcat$abstarget/wordccompinputcat$abssum
print(aggregate(cbind(abstargetprop,abssumcatnotarprop) ~ Condition,wordccompinputcat,mean))

ggplot(wordccompinputcat,aes(x=abstargetprop,y=abssumcatnotarprop,colour=Condition))+geom_point()

print("Correlation for category/target error in weak expected items")
weakexp = subset(wordccompinputcat,Condition == "WEAKCONS;EXPECTED")
print(cor(weakexp$abssumcatnotarprop,weakexp$abstargetprop))

dvlen = length(names(norawfeder.df))- which(names(norawfeder.df)=="depth")
longnoraw= melt(norawfeder.df,id.var=1:(length(norawfeder.df)-dvlen)) # make long format
print(folder) # we use folder rename html file
# add target layer for figure
#mapping = aes(x=depth, y=value, colour = Constraint,linetype=Expectation)
p1= drawERP(longnoraw,"value","Constraint","Expectation","measure","variable", timesize=-1)
p1 = p1 + facet_wrap( ~ measure+variable,scales = "free",nrow=1)
p1
```

```{r,fig.height=3,fig.width=6,warning=F}
# get example for table
tablesub = subset(norawfeder.df,layer == "word" & measure == mainMeasure)
exampleTable = tablesub[1:4,c("Constraint","Expectation","Example")]
tabletext = kable(exampleTable,format="latex",row.names=FALSE)
print(exampleTable)
interactionText=""

wordccompinput  = subset(norawfeder.df,measure == mainMeasure & layer %in% c("word",p600layer) )

if (nlevels(adultdata.df$sub) > 4){ # do mixed with more than 9 subj
  print("run models")
  # our analysis uses this set
  wordccompinput$cstrong = ifelse(wordccompinput$Constraint=="Strong",-0.5,0.5)
  wordccompinput$cexpected = ifelse(wordccompinput$Expectation=="Expected",-0.5,0.5)
  wordccompinput$cword = ifelse(wordccompinput$layer=="word",0.5,-0.5)
# - Constraint:Expectation:layer - Constraint:Expectation - Constraint:layer  - Expectation:layer
  # this is the main mixed model with centered variables
    randomeff = " + (1 + Constraint*Expectation*layer - Constraint:Expectation:layer - Constraint:layer | sub)"
  formu = as.formula(paste(dependMeasure,"~ cexpected + cstrong + cword + Constraint+Expectation+layer + sub" ))
  if (noslopes){ randomeff = " + (1 | sub)"}
  formu = as.formula(paste(dependMeasure,"~ cexpected*cstrong*cword",randomeff ))
  omnimodel = lmer(formu, wordccompinput,control=lmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=50000)))
  print(summary(omnimodel))

  modellist = modelComparison(omnimodel) # create anova table by terms subtraction

   randomeff2 = " + (1 + Constraint*Expectation | sub)"
    wordccompinputword = subset(wordccompinput, layer == "word")
  formu = as.formula(paste(dependMeasure,"~ cexpected*cstrong",randomeff2 ))
  omnimodelword = lmer(formu, wordccompinputword,control=lmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=50000)))
  print(summary(omnimodelword))
  modellistword = modelComparison(omnimodelword) # create anova table by terms subtraction

  wordccompinputhidden= subset(wordccompinput, layer == "hidden")
  omnimodelhid = lmer(formu, wordccompinputhidden,control=lmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=50000)))
  print(summary(omnimodelhid))
  modellisthid = modelComparison(omnimodelhid) # create anova table by terms subtraction
}
# create figure for paper
wordccompinput$layer= factor(wordccompinput$layer)
#mapping = aes_string(x="depth", y=dependMeasure, colour = "Constraint",linetype="Expectation")
drawERP(wordccompinput,dependMeasure,"Expectation","Constraint" , timeline.y=2)
if (!noslopes){ # when doing final version, change noslopes to FALSE
  myggsave("img/fed2007.png",width=figwidth,height=figheight) # control font size with height/width
}

n4P6cor = computeN4P6correlation(wordccompinput)
print(paste("N400/P600 correlation",n4P6cor))
```

CUT AND PASTE INTO LATEX DOC
click in box and use right arrow to see whole text

```latex
Sentential constraint was varied by manipulating the verb.  The strong sentential constraint verb \textit{sip} occurred with \textit{tea} `r counts.df$perc[counts.df$pair=="sip tea"]`\% of the time and \textit{water} `r counts.df$perc[counts.df$pair=="sip water"]`\% of the time.  The weak sentential constraint verb \textit{sniff} occurred with \textit{wine} and with \textit{water} `r counts.df$perc[counts.df$pair=="sniff water"]`\% of the time.  Word expectation can be examined by comparing the unexpected word \textit{water} and the expected words \textit{tea} and \textit{wine}.

This is an example of the stimuli used in the model
```{r,echo=FALSE,results="asis",warning=FALSE,message=FALSE}
#print(paste(tabletext,sep="",collapse="\n"))
cat(paste(tabletext))

cat(paste("\nThe maximal model for the data had random slopes",randomeff))
cat(paste(printMixedModelResults(modellist),collapse="\n"))

print("Word layer")
cat(paste(printMixedModelResults(modellistword),collapse="\n"))
print("Hidden layer")
cat(paste(printMixedModelResults(modellisthid),collapse="\n"))
```

```

## Position  Van Petten and Kutas

```{r,fig.height=8,fig.width=12}
write("vanpetten", stderr())
pos.df = subset(adultdata.df,  str_detect(adultdata.df$Condition,"(CONG|INCOH)")) # & tick < 10)

print(head(pos.df[pos.df$measure=="target",c("word","wordcat","Condition","Example","tick")])) # check
postargword.df = subset(pos.df, layer %in% c("word") & measure %in% c("output",mainMeasure) & contfunc=="C" & wordcat != "VERBD" & Condition == "CONG") 
postargword.df$verb = str_match(postargword.df$Example,"(give|throw|send|lend)")[,2]
meanbyword = aggregate(cbind(man,kite,cake) ~ tick + measure + verb + Condition,postargword.df, mean)
meanbywordlong= melt(meanbyword,id.var=1:4)

p1 = ggplot(meanbywordlong, aes(x=verb, y=value, fill = variable)) 
p1 = p1 + geom_bar(stat="identity",position="dodge") 
#p1 = p1 + facet_wrap(~ measure + tick,scales = "free",ncol=4)
p1 = p1 + facet_grid( tick ~ measure + Condition,scales = "free_y")
p1 = p1 + theme(legend.position="bottom")
p1
```


```{r,fig.height=8,fig.width=12,warning=F}
# this is for creating ERP figure
nooutput = subset(pos.df, ! measure %in% layerNotERP)
end = which(names(nooutput)=="depth")-1
first = which(names(nooutput)=="none")
norawpos.df = nooutput[,-(first:end)] # remove word specific activations/error
norawpos.df$Condition = factor(norawpos.df$Condition,labels=c("Congruent","Syntactic"))

dvlen = length(names(norawpos.df))- which(names(norawpos.df)=="depth")
longnoraw= melt(norawpos.df,id.var=1:(length(norawpos.df)-dvlen)) # make long format

# add target layer for figure
longnoraw2 = subset(longnoraw, measure == mainMeasure & contfunc == "C") #& wordcat != "VERBD"
#longnoraw2$contfunc = paste(longnoraw2$tick,longnoraw2$contfunc)
#mapping = aes(x=depth, y=value, colour = Condition,linetype=Condition)
p1= drawERP(longnoraw2,"value","Condition","variable","tick", timesize=-1)
p1 = p1 + facet_grid(tick ~ variable ,scales = "free")
#p1 = p1 + facet_wrap( ~ tick+variable)
p1
```

```{r,fig.height=3,fig.width=6}
interactionText=""
# get example for table
tablesub = subset(norawpos.df,layer == "word" & measure == mainMeasure & tick == 2)
exampleTable = tablesub[1:4,c("Condition","Example")]
tabletext = kable(exampleTable,format="latex",row.names=FALSE)
print(exampleTable)

posinput  = subset(norawpos.df,measure == mainMeasure & layer %in% c("word",p600layer) & word != "." & contfunc=="C" & wordcat %in% c("NOUNA","NOUNI"))
#posinput = subset(posinput, !str_detect(Example,"-par") )

if (nlevels(adultdata.df$sub) > 4){ # do mixed with more than 9 subj
  print("run models")
  # our analysis uses this set

  posinput$dcoher = ifelse(posinput$Condition=="Congruent",1,0)
  posinput$ccoher = ifelse(posinput$Condition=="Congruent",0.5,-0.5)
  posinput$cword = ifelse(posinput$layer=="word",0.5,-0.5)
  posinput$ctick = posinput$tick - mean(posinput$tick)
  posinput$ccontent = ifelse(posinput$contfunc=="C",0.5,-0.5)
#& wordcat != "VERBD"
  posinputnoun = subset(posinput, layer == "word")
  randomeff = paste(" + (1 + dcoher*ctick |sub)")
  if (noslopes){ randomeff = " + (1 | sub)"}
  formu = as.formula(paste(dependMeasure,"~ ctick*dcoher",randomeff ))
  omnimodel = lmer(formu, posinputnoun,control=lmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=50000)))
  print(summary(omnimodel))
  
  modellist = modelComparison(omnimodel) # create anova table by terms subtraction

  # create figure for paper
}
# & wordcat != "VERBD"
  longnoraw2 = subset(posinput,  layer == "word" )
  form = as.formula(paste(dependMeasure," ~ tick + Condition",sep=""))
  mdf = aggregate(form, longnoraw2, mean)
  mapping = aes_string(x="tick", y=dependMeasure, colour = "Condition",linetype="Condition")
  p1 = ggplot(mdf,mapping=mapping)
  #p1 = p1 + geom_line() + geom_point()
  p1 = p1 + geom_point()
  p1 = p1 + stat_smooth(method="lm",se=F)
  p1 = p1 + scale_colour_grey()
#  p1 = p1 + scale_colour_brewer( palette="Set1")
  p1 = p1 + scale_x_continuous(breaks=1:12)
  p1 = p1 + theme_bw()
  p1 = p1 +theme(legend.background = element_rect(size=.4, color="grey80")) 
  p1=p1 + theme(legend.position="bottom")+xlab("Sentence Position")+ylab("Sum Abs. Error")
  p1 = p1 + theme(panel.grid.major = element_blank(), 
                  panel.grid.minor = element_blank(),
                  panel.background = element_blank(), 
                  axis.line = element_line(colour = "black"))
  cong = str_split(exampleTable$Example[1]," ")[[1]]
  inco = str_split(exampleTable$Example[2]," ")[[1]]
  
coindf = data.frame(tick=rep(1:9,2),word=c(cong[2:10],inco[2:10]),Condition=rep(c("Congruent","Incoherent"),each=9),dependMeasure=rep(c(1.9,1.97),each=9))

#   p1=p1+geom_text(aes(x=tick, y= dependMeasure,label=word,colour = Condition),coindf,size=3)
p1
  if (!noslopes){ # when doing final version, change noslopes to FALSE
    myggsave("img/vanpetten.png",width=figwidth,height=figheight) # control font size with height/width
  }
n4P6cor = computeN4P6correlation(posinput)
print(paste("N400/P600 correlation",n4P6cor))

```

CUT AND PASTE INTO LATEX DOC
click in box and use right arrow to see whole text

```latex
Need stats to explain this

This is an example of the stimuli used in the model
```{r,echo=FALSE,results="asis",warning=FALSE,message=FALSE}
#print(paste(tabletext,sep="",collapse="\n"))
cat(paste(tabletext))

cat(paste("\nThe maximal model for the data had random slopes",randomeff))
rl = printMixedModelResults(modellist)
rl[4]=paste("@@",rl[4])
cat(paste(rl,collapse="\n"))
```

```


## AGREEMENT Hagoort et al 1993

```{r,fig.height=6,fig.width=12}
# This is Hagoort et al 1993
write("agree", stderr())
agree.df = subset(adultdata.df,  str_detect(Condition,"(PLUR|SING)") )
verbpos = which(agree.df$wordcat == "VERBT")
#verb.df = agree.df[verbpos,]
wordcatsamelen = which(agree.df$wordcat!=agree.df$wordcat[1])[1]-1  # same number of rows for each category
postverb.df = agree.df[verbpos + wordcatsamelen,] # position after verb
postverb.df=postverb.df[!is.na(postverb.df$Condition),]

cond = str_split_fixed(postverb.df$Condition,";",2)
postverb.df$Number = cond[,1]
postverb.df$Agreement = cond[,2]
postverb.df$Number = factor(postverb.df$Number,labels=c("Plural","Singular"))
postverb.df$Agreement = factor(postverb.df$Agreement,labels=c("Control","Violation"))
nc = length(postverb.df)
postverb.df = postverb.df[,c(nc-1,nc,1:(nc-2))]
xtabs(~ Agreement + Number ,postverb.df)

print(head(postverb.df[postverb.df$measure=="target",c("word","wordcat","Condition","Example","tick")])) # check

showWordOutError("the,X.ss,X.ing,X.ed,it",c("Agreement","measure","Condition"),postverb.df)
```

```{r,fig.height=4,fig.width=12}
computeClozeERPCorr(postverb.df,dependMeasure,"hidden")

corrHiddenOutputInputDeriv(postverb.df,"Agreement","Number")
```


```{r,fig.height=4,fig.width=12}
# make erp figure with different measures
#mapping = aes(x=depth, y=value, colour = Number,linetype=Agreement) 
#norawpostverbnotargout.df=removeWordsDrawERP(postverb.df,"value","Number","Agreement","variable",showFig=T)
norawpostverbnotargout.df=removeWordsDrawERP(postverb.df,"value","Agreement","Number","measure",iv5="variable",showFig=T)
```


```{r,fig.height=3,fig.width=6}
interactionText="NO TEXT"
modellist2 = list()
difflex = 0

# get example for table
agreeinputword = subset(norawpostverbnotargout.df,measure == mainMeasure  & layer == "word")
exampleTable = agreeinputword[1:4,c("Number","Agreement","Example")]
tabletext = kable(exampleTable,format="latex",row.names=FALSE)
print(exampleTable)

agreeinput  = subset(norawpostverbnotargout.df,measure == mainMeasure & layer %in% c("word",p600layer) )

if (nlevels(adultdata.df$sub) > 4){ # do mixed with more than 9 subj

  agreeinput$cplural = ifelse(agreeinput$Number=="Plural",0.5,-0.5)
  agreeinput$cviolation = ifelse(agreeinput$Agreement=="Violation",0.5,-0.5)
  agreeinput$cp6layer = ifelse(agreeinput$layer==p600layer,0.5,-0.5)

  # this is the main mixed model with centered variables
    randomeff = paste(" + (1 + cviolation*cp6layer |sub)")  #Agreement * layer 
      if (noslopes){ randomeff = " + (1 | sub)"}
  formu = as.formula(paste(dependMeasure,"~ cviolation*cp6layer",randomeff))
  omnimodel = lmer(formu, agreeinput,control=lmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=50000)))
  print(summary(omnimodel))
  modellist2 = modelComparison(omnimodel) # create anova table
  # this model is for posthocs
  formu2 = as.formula(paste(dependMeasure,"~ Agreement*layer",randomeff))
  omnimodelFactor = lmer(formu2, agreeinput)
  #print(summary(omnimodelFactor))
  model.lsmobj <- lsmeans(omnimodelFactor, ~ Agreement | layer)
  posthocs = summary(as.glht(pairs(model.lsmobj)))
  print(posthocs)
  interactionText = printInteraction(posthocs)

  difflex = abs(posthocs$`layer = word`$test$coefficients[[1]])
}
  # figure for paper
# mapping = aes_string(x="depth", y=dependMeasure, colour = "Agreement",linetype="Agreement")
  drawERP(agreeinput,dependMeasure,"Agreement",  span=1, timeline.y=5.2)
  if (!noslopes){ # when doing final version, change noslopes to FALSE
    myggsave("img/agree.png",width=figwidth,height=figheight)
  }
n4P6cor = computeN4P6correlation(agreeinput)
print(paste("N400/P600 correlation",n4P6cor))

n4P6cor = computeN4P6correlation2(agreeinput,"Control","Violation",cond="Agreement")
print(paste("N400/P600 correlation",n4P6cor))
```

CUT AND PASTE INTO LATEX DOC
click in box and use right arrow to see whole text

```latex
The model received active transitive input with singular subjects `r counts.df$perc[counts.df$pair=="TRANS SG"]`\% of the time and plural subjects `r counts.df$perc[counts.df$pair=="TRANS PL"]`\% of the time. 

This is an example of the stimuli used in the model.

```{r,echo=FALSE,results="asis",warning=FALSE,message=FALSE}
#print(paste(tabletext,sep="",collapse="\n"))
cat(paste(tabletext))

cat(paste("\nThe maximal model for the data had random slopes",randomeff))
cat(paste(printMixedModelResults(modellist2),collapse="\n"))

cat(paste("\n",interactionText,sep=""))
```
```




## Tense  Allen et al. (2003)

```{r,fig.height=4,fig.width=12}
write("tense", stderr())
tense.df = subset(adultdata.df,  str_detect(Condition,"(TENSECONT|TENSEVIOL)") )
tense.df$Condition = factor(tense.df$Condition,labels=c("Control","Violation"))
verbpos = which(tense.df$wordcat == "VERBT")
wordcatsamelen = which(tense.df$wordcat!=tense.df$wordcat[1])[1]-1
verb.df = tense.df[verbpos,] #  verb
postverb.df = tense.df[verbpos + wordcatsamelen,] # position after verb
postverb.df=postverb.df[!is.na(postverb.df$Condition),]

print(head(postverb.df[postverb.df$measure=="target",c("word","wordcat","Condition","Example","tick")]))

showWordOutError("the,a,X.ss,X.ing,X.ed,X.par",c("Condition","measure"),postverb.df)

```

```{r,fig.height=4,fig.width=12}
corrHiddenOutputInputDeriv(postverb.df,"Condition")
myggsave("img/actderivtense.png",width=6,height=6)
```

```{r,fig.height=4,fig.width=12}
# make erp figure with different measures
norawpostverbnotargout.df=removeWordsDrawERP(postverb.df,"value","Condition")

```

```{r,fig.height=3,fig.width=6}
interactionText="NO TEXT"
modellist2 = list()
# get example for table
tenseexampleword = subset(norawpostverbnotargout.df,measure == mainMeasure  & layer == "word")
exampleTable = tenseexampleword[1:2,c("Condition","Example")]
tabletext = kable(exampleTable,format="latex",row.names=FALSE)
print(exampleTable)

 tenseinput  = subset(norawpostverbnotargout.df,measure == mainMeasure & layer %in% c("word",p600layer) )

if (nlevels(adultdata.df$sub) > 4){ # do mixed with more than 9 subj
 
  tenseinput$cviolation = ifelse(tenseinput$Condition=="Violation",0.5,-0.5) # one against two
  tenseinput$cp600layer = ifelse(tenseinput$layer==p600layer,0.5,-0.5)

  # this is the main mixed model with centered variables
  randomeff = paste(" + (1 +  cviolation*cp600layer |sub)")  # Condition*layer
  if (noslopes){ randomeff = " + (1 | sub)"}
  formu = as.formula(paste(dependMeasure,"~ cviolation*cp600layer",randomeff))
  omnimodel = lmer(formu, tenseinput,control=lmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=50000)))
  print(summary(omnimodel))
  modellist2 = modelComparison(omnimodel) # create anova table

  # this model is for posthocs
  formu2 = as.formula(paste(dependMeasure,"~ Condition*layer",randomeff))
  omnimodelFactor = lmer(formu2, tenseinput)
  #print(summary(omnimodelFactor))
  model.lsmobj <- lsmeans(omnimodelFactor, ~ Condition | layer)
  posthocs = summary(as.glht(pairs(model.lsmobj)))
  print(posthocs)
  interactionText = printInteraction(posthocs)
  difflex = difflex + abs(posthocs$`layer = word`$test$coefficients[[1]])

}
  # figure for paper
 # mapping = aes_string(x="depth", y=dependMeasure, colour = "Condition",linetype="Condition")
  drawERP(tenseinput,dependMeasure,"Condition",  timeline.y=8,span=.8)
  if (!noslopes){ # when doing final version, change noslopes to FALSE
    myggsave("img/tense.png",width=figwidth,height=figheight)
  }
  
n4P6cor = computeN4P6correlation(tenseinput)
print(paste("N400/P600 correlation",n4P6cor))

n4P6cor = computeN4P6correlation2(tenseinput,"Control","Violation")
print(paste("N400/P600 correlation",n4P6cor))

```

CUT AND PASTE INTO LATEX DOC
click in box and use right arrow to see whole text

```latex

This is an example of the stimuli used in the model.

```{r,echo=FALSE,results="asis",warning=FALSE,message=FALSE}
#print(paste(tabletext,sep="",collapse="\n"))
cat(paste(tabletext))

cat(paste("\nThe maximal model for the data had random slopes",randomeff))
cat(paste(printMixedModelResults(modellist2),collapse="\n"))

cat(paste("\n",interactionText,sep=""))
```
```


## WORDCAT (Wassenaar and Hagoort, 2005)

```{r,fig.height=4,fig.width=5}
write("wordcat", stderr())
cat.df = subset(adultdata.df,  str_detect(Condition,"(CATCONT|CATVIOL)") )
cat.df$Condition=factor(cat.df$Condition,labels=c("Control","Violation"))
verbpos = which(cat.df$wordcat == "VERBI")
wordcatsamelen = which(cat.df$wordcat!=cat.df$wordcat[1])[1]-1
verb.df = cat.df[verbpos,] #  verb
postverb.df = cat.df[verbpos + wordcatsamelen,] # position after verb
postverb.df=postverb.df[!is.na(postverb.df$Condition),]

print(head(postverb.df[postverb.df$measure=="target",c("word","wordcat","Condition","Example","tick")])) # check

showWordOutError("X.ed,X.s,per",c("Condition","measure"),postverb.df)
```


```{r,fig.height=4,fig.width=12}
corrHiddenOutputInputDeriv(postverb.df,"Condition")
```

```{r,fig.height=4,fig.width=12}

#mapping = aes(x=depth, y=value, colour = Condition,linetype=Condition) 
norawpostverbnotargout.df=removeWordsDrawERP(postverb.df,"value", "Condition")

```

```{r,fig.height=3,fig.width=6}
interactionText="NO TEXT"
modellist2 = list()

# get example for table
catwordexample = subset(norawpostverbnotargout.df,measure == mainMeasure  & layer == "word")
exampleTable = catwordexample[1:4,c("Condition","Example")]
tabletext = kable(exampleTable,format="latex",row.names=FALSE)
print(exampleTable)

catinput  = subset(norawpostverbnotargout.df,measure == mainMeasure & layer %in% c("word",p600layer) )

if (nlevels(adultdata.df$sub) > 4){ # do mixed with more than 9 subj

  catinput$cviolation = ifelse(catinput$Condition=="Violation",0.5,-0.5) # one against two
  catinput$cp600layer = ifelse(catinput$layer==p600layer,0.5,-0.5)

  # this is the main mixed model with centered variables
  randomeff = paste(" + (1 + Condition * layer |sub)")
    if (noslopes){ randomeff = " + (1 | sub)" }
  formu = as.formula(paste(dependMeasure,"~ cviolation*cp600layer",randomeff))
  omnimodel = lmer(formu, catinput,control=lmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=50000)))
  print(summary(omnimodel))
  modellist2 = modelComparison(omnimodel) # create anova table

  # this model is for posthocs
  formu2 = as.formula(paste(dependMeasure,"~ Condition*layer",randomeff))
  omnimodelFactor = lmer(formu2, catinput)
  #print(summary(omnimodelFactor))
  model.lsmobj <- lsmeans(omnimodelFactor, ~ Condition | layer)
  posthocs = summary(as.glht(pairs(model.lsmobj)))
  print(posthocs)
  interactionText = printInteraction(posthocs)
  difflex = difflex + abs(posthocs$`layer = word`$test$coefficients[[1]])

}
  # figure for paper
#  mapping = aes_string(x="depth", y=dependMeasure, colour = "Condition",linetype="Condition")
  drawERP(catinput,dependMeasure,"Condition", timeline.y=4,span=0.8)
  if (!noslopes){ # when doing final version, change noslopes to FALSE??n
    myggsave("img/cat.png",width=figwidth,height=figheight)
  }
  
n4P6cor = computeN4P6correlation(catinput)
print(paste("N400/P600 correlation",n4P6cor))

n4P6cor = computeN4P6correlation2(catinput,"Control","Violation")
print(paste("N400/P600 correlation",n4P6cor))
```

CUT AND PASTE INTO LATEX DOC
click in box and use right arrow to see whole text

```latex

This is an example of the stimuli used in the model.

```{r,echo=FALSE,results="asis",warning=FALSE,message=FALSE}
#print(paste(tabletext,sep="",collapse="\n"))
cat(paste(tabletext))

cat(paste("\nThe maximal model for the data had random slopes",randomeff))
cat(paste(printMixedModelResults(modellist2),collapse="\n"))

cat(paste("\n",interactionText,sep=""))
```
```



## SUBCAT  Osterhout and Holcomb (1992)

```{r,fig.height=4,fig.width=12}
write("subcat", stderr())
sub.df = subset(adultdata.df,  str_detect(Condition,"(SUBCONT|SUBVIOL)") )
sub.df$Condition=factor(sub.df$Condition,labels=c("Control","Violation"))
preppos = which(sub.df$word %in% c("near","by"))
prep.df = sub.df[preppos,] #  verb

print(head(prep.df[prep.df$measure=="target",c("word","wordcat","Condition","Example","tick")])) # check

showWordOutError("near,by,the,per",c("Condition","measure"),prep.df)

```


```{r,fig.height=4,fig.width=12}
corrHiddenOutputInputDeriv(prep.df,"Condition")
```

```{r,fig.height=4,fig.width=12}
#mapping = aes(x=depth, y=value, colour = Condition,linetype=Condition) 
norawprepnotargout.df=removeWordsDrawERP(prep.df,"value","Condition")
```

```{r,fig.height=3,fig.width=6}
interactionText="NO TEXT"
modellist2 = list()

# get example for table
catwordexample = subset(norawprepnotargout.df,measure == mainMeasure  & layer == "word")
exampleTable = catwordexample[1:4,c("Condition","Example")]
tabletext = kable(exampleTable,format="latex",row.names=FALSE)
print(exampleTable)

subinput  = subset(norawprepnotargout.df,measure == mainMeasure & layer %in% c("word",p600layer) )

if (nlevels(adultdata.df$sub) > 4){ # do mixed with more than 9 subj

  subinput$cviolation = ifelse(subinput$Condition=="Violation",0.5,-0.5) # one against two
  subinput$cp600layer = ifelse(subinput$layer==p600layer,0.5,-0.5)

  # this is the main mixed model with centered variables
  randomeff = paste(" + (1 + cviolation*cp600layer |sub)")
    if (noslopes){ randomeff = " + (1 | sub)"}
  formu = as.formula(paste(dependMeasure,"~ cviolation*cp600layer",randomeff))
  omnimodel = lmer(formu, subinput,control=lmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=50000)))
  print(summary(omnimodel))
  modellist2 = modelComparison(omnimodel) # create anova table

  # this model is for posthocs
  formu2 = as.formula(paste(dependMeasure,"~ Condition*layer",randomeff))
  omnimodelFactor = lmer(formu2, subinput)
  #print(summary(omnimodelFactor))
  model.lsmobj <- lsmeans(omnimodelFactor, ~ Condition | layer)
  posthocs = summary(as.glht(pairs(model.lsmobj)))
  print(posthocs)
  interactionText = printInteraction(posthocs)
    difflex = difflex + abs(posthocs$`layer = word`$test$coefficients[[1]])

}

  # figure for paper
    #mapping = aes_string(x="depth", y=dependMeasure, colour = "Condition",linetype="Condition")
  drawERP(subinput,dependMeasure,"Condition", timeline.y=4.7)
  if (!noslopes){ # when doing final version, change noslopes to FALSE
    myggsave("img/subjcat.png",width=figwidth,height=figheight)
  }
  
n4P6cor = computeN4P6correlation(subinput)
print(paste("N400/P600 correlation",n4P6cor))

n4P6cor = computeN4P6correlation2(subinput,"Control","Violation")
print(paste("N400/P600 correlation",n4P6cor))

```

CUT AND PASTE INTO LATEX DOC
click in box and use right arrow to see whole text

```latex

This is an example of the stimuli used in the model.

```{r,echo=FALSE,results="asis",warning=FALSE,message=FALSE}
#print(paste(tabletext,sep="",collapse="\n"))
cat(paste(tabletext))

cat(paste("\nThe maximal model for the data had random slopes",randomeff))
cat(paste(printMixedModelResults(modellist2),collapse="\n"))

cat(paste("\n",interactionText,sep=""))
```
```


## GARDEN PATH

```{r,fig.height=4,fig.width=12}
write("garden", stderr())
garden.df = subset(adultdata.df,  str_detect(Condition,"(GARDSC|GARDAMB)") & tick > 4 )
garden.df$Condition=factor(garden.df$Condition,labels=c("Unambiguous","Ambiguous"),levels=c("GARDSC","GARDAMB"))
garden.df$tarword = str_match(garden.df$Example,"(believe|know)(.*?) (the|a) ([A-z]+)( -s)* ([A-z.]+)*")[,7]
garden.df$strlen = sapply(gregexpr("[^ ]+", garden.df$Example), function(x) sum(x > 0))
gardenpos = which(garden.df$word == garden.df$tarword)
gardentar.df = garden.df[gardenpos,] #  verb
gardentar.df= subset(gardentar.df,strlen != tick)
gardentar.df$strlen = NULL
gardentar.df$tarword = NULL

print(head(gardentar.df[gardentar.df$measure=="target",c("word","wordcat","Condition","Example","tick")])) # check

showWordOutError("is,are,will,was,were,jump,run,walk,nap,per",c("Condition","measure"),gardentar.df)
```


```{r,fig.height=4,fig.width=12}
corrHiddenOutputInputDeriv(gardentar.df,"Condition")
```


```{r,fig.height=4,fig.width=12}
#mapping = aes(x=depth, y=value, colour = Condition,linetype=Condition) 
norawgardennotargout.df=removeWordsDrawERP(gardentar.df,"value","Condition")
```

```{r,fig.height=3,fig.width=6}
interactionText="NO TEXT"
modellist2 = list()

# get example for table
gardenexample = subset(norawgardennotargout.df,measure == mainMeasure  & layer == "word")
exampleTable = gardenexample[1:6,c("Condition","Example")]
tabletext = kable(exampleTable,format="latex",row.names=FALSE)
print(exampleTable)

gardeninput  = subset(norawgardennotargout.df,measure == mainMeasure & layer %in% c("word",p600layer) )

if (nlevels(adultdata.df$sub) > 4){ # do mixed with more than 9 subj
  gardeninput$cviolation = ifelse(gardeninput$Condition=="Ambiguous",0.5,-0.5) # one against two
  gardeninput$cp600layer = ifelse(gardeninput$layer==p600layer,0.5,-0.5)

  # this is the main mixed model with centered variables
  randomeff = paste(" + (1+ cviolation*cp600layer |sub)") # Condition * layer
    if (noslopes){ randomeff = " + (1 | sub)"}
    print(paste("************        RandomEffect ->",randomeff))
  formu = as.formula(paste(dependMeasure,"~ cviolation*cp600layer",randomeff))
  omnimodel = lmer(formu, gardeninput,control=lmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=50000)))
  print(summary(omnimodel))
    modellist2 = modelComparison(omnimodel) # create anova table

  # this model is for posthocs
  formu2 = as.formula(paste(dependMeasure,"~ Condition*layer",randomeff))
  omnimodelFactor = lmer(formu2, gardeninput)
  #print(summary(omnimodelFactor))
  model.lsmobj <- lsmeans(omnimodelFactor, ~ Condition | layer)
  posthocs = summary(as.glht(pairs(model.lsmobj)))
  print(posthocs)
  interactionText = printInteraction(posthocs)
  difflex = difflex + abs(posthocs$`layer = word`$test$coefficients[[1]])

}
  # figure for paper
#    mapping = aes_string(x="depth", y=dependMeasure, colour = "Condition",linetype="Condition")
  drawERP(gardeninput,dependMeasure, "Condition", timeline.y=2.2)
  if (!noslopes){ # when doing final version, change noslopes to FALSE
    myggsave("img/garden.png",width=figwidth,height=figheight)
  }
  
n4P6cor = computeN4P6correlation(gardeninput)
print(paste("N400/P600 correlation",n4P6cor))

n4P6cor = computeN4P6correlation2(gardeninput,"Unambiguous","Ambiguous")
print(paste("N400/P600 correlation",n4P6cor))

```

CUT AND PASTE INTO LATEX DOC
click in box and use right arrow to see whole text

```latex
UPDATE THIS

This is an example of the stimuli used in the model.

```{r,echo=FALSE,results="asis",warning=FALSE,message=FALSE}
#print(paste(tabletext,sep="",collapse="\n"))
cat(paste(tabletext))

cat(paste("\nThe maximal model for the data had random slopes",randomeff))

cat(paste(printMixedModelResults(modellist2),collapse="\n"))

cat(paste("\n",interactionText,sep=""))
```
```



## Semantic P6 (Kim and Osterhout)

```{r,fig.height=4,fig.width=10}
write("semP6", stderr())
semP6.df = subset(adultdata.df,  str_detect(Condition,"(PASSCONT|ACTCONT|SEMATTR|NOATTR)") )
semP6.df$Condition = factor(semP6.df$Condition, labels=c("Active Control","Passive Control", "Role Reversal"),levels = c("ACTCONT","PASSCONT","SEMATTR"))
#"NOATTR", "No Attractor",
verbpos = which(semP6.df$wordcat == "VERBT")
wordcatsamelen = which(semP6.df$wordcat!=semP6.df$wordcat[1])[1]-1
verb.df = semP6.df[verbpos,] #  verb
postverb.df = semP6.df[verbpos + wordcatsamelen,] # position after verb
postverb.df=postverb.df[!is.na(postverb.df$Condition),]

print(head(postverb.df[postverb.df$measure=="target",c("word","wordcat","Condition","Example","tick")])) # check

showWordOutError("the,a,X.ss,X.ing,X.ed,X.par",c("Condition","measure"),postverb.df)
showWordOutError("the,a,X.ss,X.ing,X.ed,X.par",c("Condition","measure"),verb.df)

```

```{r,fig.height=4,fig.width=12}
computeClozeERPCorr(postverb.df,dependMeasure,"word")
computeClozeERPCorr(postverb.df,dependMeasure,"hidden")

corrHiddenOutputInputDeriv(postverb.df,"Condition")
```


```{r,fig.height=4,fig.width=12}
#mapping = aes_string(x="depth", y="value", colour = "Condition",linetype="Condition")
norawpostverbnotargout.df=removeWordsDrawERP(postverb.df,"value","Condition")
norawverbnotargout.df=removeWordsDrawERP(verb.df,"value","Condition")
```

```{r,fig.height=3,fig.width=6}
interactionText="NO TEXT"
modellist2 = list()
#norawpostverbnotargout.df=subset(norawpostverbnotargout.df,Condition != "No Attractor")
#norawpostverbnotargout.df=norawpostverbnotargout.df

# get example for table
semP6exampleword = subset(norawpostverbnotargout.df,measure == mainMeasure  & layer == "word")
exampleTable = semP6exampleword[1:12,c("Condition","Example")]
tabletext = kable(exampleTable,format="latex",row.names=FALSE)
print(exampleTable)

semP6input  = subset(norawpostverbnotargout.df,measure == mainMeasure & layer %in% c("word",p600layer) )
semP6inputverb  = subset(norawverbnotargout.df,measure == mainMeasure & layer %in% c("word",p600layer) )

if (nlevels(adultdata.df$sub) > 4){ # do mixed with more than 9 subj

  options(contrasts=c("contr.treatment", "contr.treatment"))
#  semP6input$Condition = factor(semP6input$Condition,levels=c("Active Control", "Passive Control", "No Attractor", "Semantic Attractor"))
  semP6input$cpassive = 0
  semP6input$cpassive[semP6input$Condition=="Passive Control"]= 0.5
  semP6input$cpassive[semP6input$Condition=="Active Control"]=  -0.5
  semP6input$semattvsgram = 0
  semP6input$semattvsgram[semP6input$Condition=="Role Reversal"] = 1
  semP6input$semattvsgram[semP6input$Condition%in% c("Passive Control","Active Control")] = -0.5
    semP6input$cp600layer = ifelse(semP6input$layer==p600layer,0.5,-0.5)

  # this is the main mixed model with centered variables
  randomeff = paste(" + (1 + cp600layer  |sub)") # Condition * layer
    if (noslopes){ randomeff = " + (1 | sub)"}
  formu = as.formula(paste(dependMeasure,"~   cp600layer*cpassive + cp600layer*semattvsgram ",randomeff))
  omnimodel = lmer(formu, semP6input,control=lmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=50000)))
  print(summary(omnimodel))
  modellist2 = modelComparison(omnimodel) # create anova table

  maincond = anova(modellist2[[3]],modellist2[[5]])
  condlayer = anova(modellist2[[1]],modellist2[[3]])
  
    # this model is for posthocs
  semP6input$semattvsgramf = factor(semP6input$semattvsgram,labels=c("ActPas","RoleRev"))
  formu2 = as.formula(paste(dependMeasure,"~  layer*semattvsgramf",randomeff))
  omnimodelFactor = lmer(formu2, semP6input)
  #print(summary(omnimodelFactor))
  model.lsmobj <- lsmeans(omnimodelFactor, ~ semattvsgramf | layer)
  posthocs = summary(as.glht(pairs(model.lsmobj)))
  print(posthocs)
  interactionText = printInteraction(posthocs)
  difflexSemP6 =  abs(posthocs$`layer = word`$test$coefficients[[1]])
  avedifflex = difflex/5
  print(paste("Ratio of lexical sem P6 vs other P6",difflexSemP6/avedifflex))
  
}
  # figure for paper
semP6input[semP6input$Condition == "Passive Control",dependMeasure]=   0.1+semP6input[semP6input$Condition == "Passive Control",dependMeasure]
#   mapping = aes_string(x="depth", y=dependMeasure, colour = "Condition",linetype="Condition")
  p = drawERP(semP6input,dependMeasure,"Condition", timeline.y=6)
  p = p + scale_linetype_manual(values=c("dotted","dashed","solid")) #
  p
  if (!noslopes){ # when doing final version, change noslopes to FALSE
    myggsave("img/semP6.png",width=figwidth,height=figheight)
  }
#   mapping = aes_string(x="depth", y=dependMeasure, colour = "Condition",linetype="Condition")
#  drawERP(semP6inputverb,mapping, timeline.y=6)
  
n4P6cor = computeN4P6correlation(semP6input)
print(paste("N400/P600 correlation",n4P6cor))

```

CUT AND PASTE INTO LATEX DOC
click in box and use right arrow to see whole text

```latex

This is an example of the stimuli used in the model.

```{r,echo=FALSE,results="asis",warning=FALSE,message=FALSE}
#print(paste(tabletext,sep="",collapse="\n"))
cat(paste(tabletext))

cat(paste("\nThe maximal model for the data had random slopes",randomeff))

cat(paste("\nmain effect",reportChisqur("",maincond)[[1]]))
cat(paste("\ninteraction",reportChisqur("",condlayer)[[1]]))

cat(paste(printMixedModelResults(modellist2),collapse="\n"))

cat(paste("\n",interactionText,sep=""))
```
```

## WORDCAT DEVELOP

```{r,fig.height=8,fig.width=8}
write("dev wordcat", stderr())
cat.df = subset(develop.df,str_detect(Condition,"(CATCONT|CATVIOL)") & ! measure %in% c("error", "myoutputder","myinputder","outderiv")) 

cat.df$Condition=factor(cat.df$Condition,labels=c("Control","Violation"))
verbpos = which(cat.df$wordcat == "VERBI")
wordcatsamelen = which(cat.df$wordcat!=cat.df$wordcat[1])[1]-1
verb.df = cat.df[verbpos,] #  verb
postverb.df = cat.df[verbpos + wordcatsamelen,] # position after verb
postverb.df=postverb.df[!is.na(postverb.df$Condition),]
postverb.df=postverb.df[!is.na(postverb.df$Condition),]

print(head(postverb.df[postverb.df$measure=="target",c("word","wordcat","Condition","Example","tick","epoch")])) # check

postverb2.df = subset(postverb.df, layer == "word")
postverb2.df$X.s=abs(postverb2.df$X.s)
postverb2.df$X.ss=abs(postverb2.df$X.ss)
postverb2.df$per=abs(postverb2.df$per)
p1=showWordOutError("X.ed,X.s,per",c("Condition","epoch","measure"),postverb2.df)
p1=p1+theme_bw()+ylab("Activation/Error")
#p1 =p1 + scale_fill_discrete(name="Word Unit",labels=c("3rdSingular", "Plural", "End of sentence"))
p1 = p1+ theme(legend.position="bottom")
p1
#myggsave("img/devoutput.png",width=figwidth,height=figheight)
```


```{r,fig.height=6,fig.width=8}
corrHiddenOutputInputDeriv(postverb.df,"Condition","epoch")
```

```{r,fig.height=4,fig.width=8}

epochnum = which(names(postverb.df)=="epoch")
postverb2.df = postverb.df[,c(epochnum,1:epochnum-1,(epochnum+1):length(postverb.df))]
mapping = aes(x=depth, y=value, colour = Condition,linetype=Condition) 
norawpostverbnotargout.df=removeWordsDrawERP(postverb.df,"value", "Condition", "epoch")

```

```{r,fig.height=3,fig.width=6}
interactionText="NO TEXT"
modellist2 = list()

childtime = 30000
certainepochs.df = subset(norawpostverbnotargout.df, epoch %in% c(childtime,100000))
#certainepochs.df = norawpostverbnotargout.df

# get example for table
catwordexample = subset(certainepochs.df,measure == mainMeasure  & layer == "word")
exampleTable = catwordexample[1:4,c("Condition","Example")]
tabletext = kable(exampleTable,format="latex",row.names=FALSE)
print(exampleTable)
catinput  = subset(certainepochs.df,measure == mainMeasure & layer %in% c("word",p600layer) )

if (nlevels(adultdata.df$sub) > 4){ # do mixed with more than 9 subj

  catinput$cviolation = ifelse(catinput$Condition=="Violation",0.5,-0.5) # one against two
  catinput$cword = ifelse(catinput$layer=="word",0.5,-0.5)
  catinput$cepoch = scale(catinput$epoch)
  catinput$sub = factor(catinput$sub)
  # this is the main mixed model with centered variables
  randomeff = paste(" + (1 + Condition |sub)")   # Condition * epoch 
  if (noslopes){ randomeff = " + (1 | sub)"}
  formu = as.formula(paste(dependMeasure,"~ cviolation*cepoch*cword",randomeff))
  omnimodel = lmer(formu, catinput,control=lmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=50000)))
  print(summary(omnimodel))
#  modellist2 = modelComparison(omnimodel) # create anova table

  catinputword = subset(catinput,layer == "word")
  catinputword$cviolation = ifelse(catinputword$Condition=="Violation",0.5,-0.5) # one against two
  catinputword$cword = ifelse(catinputword$layer=="word",0.5,-0.5)
  catinputword$cepoch = scale(catinputword$epoch)
  catinputword$sub = factor(catinputword$sub)
  # this is the main mixed model with centered variables
  randomeff = paste(" + (1 + Condition  |sub)")   # Condition * epoch 
  if (noslopes){ randomeff = " + (1 | sub)"}
  formu = as.formula(paste(dependMeasure,"~ cviolation*cepoch",randomeff))
  omnimodel = lmer(formu, catinputword,control=lmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=50000)))
  print(summary(omnimodel))
  
  modellist2 = modelComparison(omnimodel) # create anova table
  
  # this model is for posthocs
  catinputword$depoch = factor(catinputword$epoch)
  formu2 = as.formula(paste(dependMeasure,"~ Condition*depoch",randomeff))
  omnimodelFactor = lmer(formu2, catinputword)
  print(summary(omnimodelFactor))
  model.lsmobj <- lsmeans(omnimodelFactor, ~ Condition | depoch)
  posthocs = summary(as.glht(pairs(model.lsmobj)))
  print(posthocs)
  interactionText = printInteraction(posthocs)

}

form = as.formula(paste(dependMeasure," ~ Condition + epoch + layer",sep=""))
meandf = aggregate(form, catinput, mean)
mapping = aes_string(x="epoch", y=dependMeasure, fill = "Condition")
meandf$epoch= factor(meandf$epoch)
p=ggplot(meandf, mapping)
p=p+geom_bar(position="dodge",stat="identity")
p = p + scale_fill_brewer(palette = "Set1")
p=p+facet_wrap(~ layer)
p=p + theme(panel.grid.major = element_blank(), 
                  panel.grid.minor = element_blank(),
                  panel.background = element_blank(), 
                  axis.line = element_line(colour = "black"))
p

catinputword = subset(catinput, layer == "word")

form = as.formula(paste(dependMeasure," ~ Condition + epoch ",sep=""))
meandf = aggregate(form, catinputword, mean)
mapping = aes_string(x="epoch", y=dependMeasure, fill = "Condition")
meandf$epoch= factor(meandf$epoch,labels = c(paste(childtime,"(child)",sep=""),"100000(adult)"))
p=ggplot(meandf, mapping)
p=p+geom_bar(position="dodge",stat="identity")+theme_bw()
#p = p + scale_fill_brewer(palette = "Set1")  
p = p + scale_fill_grey(start = 0.25, end = 0.75)
p = p +ylab("Sum Abs. Error")+xlab("Testing Epoch")
p=p + theme(panel.grid.major = element_blank(), 
                  panel.grid.minor = element_blank(),
                  panel.background = element_blank(), 
                  axis.line = element_line(colour = "black"))
p

  if (!noslopes){ # when doing final version, change noslopes to FALSE??n
    myggsave("img/catdevelop.png",width=figwidth,height=figheight)
  }
```

CUT AND PASTE INTO LATEX DOC
click in box and use right arrow to see whole text

```latex

This is an example of the stimuli used in the model.

```{r,echo=FALSE,results="asis",warning=FALSE,message=FALSE}
#print(paste(tabletext,sep="",collapse="\n"))
cat(paste(tabletext))

cat(paste("\nThe maximal model for the data had random slopes",randomeff))

cat(paste(printMixedModelResults(modellist2),collapse="\n"))

cat(paste("\n",interactionText,sep=""))
```
```


## Coulson et al

```{r,fig.height=6,fig.width=12}
# This is Coulson et al 
write("Coulson et al", stderr())
coulagree.df = subset(couldf,  str_detect(Condition,"(SING|PLUR)") )
verbpos = which(coulagree.df$wordcat == "VERBT")
wordcatsamelen = which(coulagree.df$wordcat!=coulagree.df$wordcat[1])[1]-1
verb.df = coulagree.df[verbpos,] #  verb
postverbcoul.df = coulagree.df[verbpos + wordcatsamelen,] # position after verb
postverbcoul.df=postverbcoul.df[!is.na(postverbcoul.df$Condition),]

postverbcoul.df = cbind(Probability="",Number="",Agreement="",postverbcoul.df)
cond = str_split_fixed(postverbcoul.df$Condition,";",2)
postverbcoul.df$Number = cond[,1]
postverbcoul.df$Agreement = cond[,2]
postverbcoul.df$Number = factor(postverbcoul.df$Number,labels=c("Singular"))
postverbcoul.df$Agreement = factor(postverbcoul.df$Agreement,labels=c("Control","Violation"))
postverbcoul.df$Probability=NA
postverbcoul.df$Probability[postverbcoul.df$Agreement=="Violation" & str_detect(postverbcoul.df$coul,"vcoul1")] = "Improbable"
postverbcoul.df$Probability[postverbcoul.df$Agreement=="Violation" & str_detect(postverbcoul.df$coul,"vcoul2")] = "Probable"
postverbcoul.df$Probability[postverbcoul.df$Agreement=="Control" & str_detect(postverbcoul.df$coul,"vcoul2")] = "Improbable"
postverbcoul.df$Probability[postverbcoul.df$Agreement=="Control" & str_detect(postverbcoul.df$coul,"vcoul1")] = "Probable"
postverbcoul.df$Probability=factor(postverbcoul.df$Probability)

xtabs(~ Agreement +Probability,postverbcoul.df)

print(head(postverbcoul.df[postverbcoul.df$measure=="target",c("word","wordcat","Condition","Example","tick")])) # check

showWordOutError("the,a,X.ss,X.ed",c("Agreement","measure","coul"),postverbcoul.df)
```


```{r,fig.height=4,fig.width=12}
corrHiddenOutputInputDeriv(postverbcoul.df,"Probability", "Agreement")
```


```{r,fig.height=4,fig.width=12}
# make erp figure with different measures
#mapping = aes(x=depth, y=value, colour = Agreement,linetype=Probability) 
coulnorawpostverbnotargout.df=removeWordsDrawERP(postverbcoul.df,"value","Probability","Agreement")
```


```{r,fig.height=3,fig.width=6}
interactionText="NO TEXT"
modellist2 = list()

# get example for table
agreeinputword = subset(coulnorawpostverbnotargout.df,measure == mainMeasure  & layer == "word")
exampleTable = agreeinputword[1:4,c("Number","Agreement","Example")]
tabletext = kable(exampleTable,format="latex",row.names=FALSE)
print(exampleTable)

coulagreeinput  = subset(coulnorawpostverbnotargout.df,measure == mainMeasure & layer %in% c("word",p600layer) )

if (nlevels(adultdata.df$sub) > 4){ # do mixed with more than 9 subj

  coulagreeinput$cplural = ifelse(coulagreeinput$Number=="Plural",0.5,-0.5)
  coulagreeinput$cviolation = ifelse(coulagreeinput$Agreement=="Violation",0.5,-0.5)
  coulagreeinput$cp6layer = ifelse(coulagreeinput$layer==p600layer,0.5,-0.5)
  coulagreeinput$cprob = ifelse(coulagreeinput$Probability=="Probable",0.5,-0.5)

  #- cviolation:cp6layer:cprob  -cviolation:cp6layer - cviolation:cprob - cp6layer:cprob - cp6layer
  # this is the main mixed model with centered variables
  #cviolation*cp6layer*cprob -cviolation:cp6layer:cprob -cviolation:cp6layer -cviolation:cprob - cp6layer:cprob - cp6layer -cviolation -cprob
    randomeff = paste(" + (1 + cviolation*cp6layer*cprob - cviolation:cp6layer:cprob |sub)")  #cviolation*cp6layer*cprob
      if (noslopes){ randomeff = " + (1 | sub)"}
  formu = as.formula(paste(dependMeasure,"~ cviolation*cp6layer*cprob",randomeff))
  omnimodel = lmer(formu, coulagreeinput,control=lmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=50000)))
  print(summary(omnimodel))
  
  modellist2 = modelComparison(omnimodel) # create anova table
  # this model is for posthocs
  formu2 = as.formula(paste(dependMeasure,"~ Probability*layer",randomeff))
  omnimodelFactor = lmer(formu2, coulagreeinput)
#  print(summary(omnimodelFactor))
  model.lsmobj <- lsmeans(omnimodelFactor, ~ Probability | layer)
  posthocs = summary(as.glht(pairs(model.lsmobj)))
  print(posthocs)
  interactionText = printInteraction(posthocs)

}

xtabs(~ coul + Agreement, coulagreeinput)
xtabs(~ Probability + Agreement, coulagreeinput)
# mapping = aes_string(x="depth", y=dependMeasure, colour = "Probability",linetype="Probability")
      p = drawERP(coulagreeinput,dependMeasure,"Probability",iv4="Agreement", span=1, timeline.y=4,timesize=2,xmax=7)
 #     p = p + facet_wrap(~ Agreement)
      p
  if (!noslopes){ # when doing final version, change noslopes to FALSE
    myggsave("img/agreelearn.png",width=figwidth,height=figheight)
  }

```

CUT AND PASTE INTO LATEX DOC
click in box and use right arrow to see whole text

```latex

This is an example of the stimuli used in the model.

```{r,echo=FALSE,results="asis",warning=FALSE,message=FALSE}
#print(paste(tabletext,sep="",collapse="\n"))
cat(paste(tabletext))

cat(paste("\nThe maximal model for the data had random slopes",randomeff))

cat(paste(printMixedModelResults(modellist2),collapse="\n"))

# probablity x layer interaction
cat(paste("\n",interactionText,sep=""))
```
```


## Rommer Federmeier

```{r,fig.height=4,fig.width=12}
# This is Coulson et al 
write("Rommer Federmeier", stderr())
romFinalN = subset(rommerdf, wordcat %in% c('NOUNI'))
showWordOutError("coffee,tea,wine,beer,water,cake",c("Condition","measure"),romFinalN)
romFinalN$vrom=NULL
romFinalN$Condition = str_replace(romFinalN$Condition," +","")
romFinalNtest= subset(romFinalN, Condition %in% c("TEST-UNPRED","TEST-PRED"))

print(head(romFinalNtest[romFinalNtest$measure=="target",c("word","wordcat","Condition","Example","tick")])) # check

# check that layers are the right size

showWordOutError("coffee,tea,wine,beer,water,cake",c("Condition","measure"),romFinalNtest)
```

```{r,fig.height=4,fig.width=12}
# make erp figure with different measures
#mapping = aes(x=depth, y=value, colour = Condition,linetype=Condition)
romrawpostverbnotargout.df=removeWordsDrawERP(romFinalNtest,"value","Condition","measure","variable",showFig=TRUE)
rominput  = subset(romrawpostverbnotargout.df,measure == mainMeasure & layer %in% c("word",p600layer) )
rominput$Prime = factor(rominput$Condition,labels=c("Predictable","Unpredictable"))

romNotFinalN = subset(rommerNotdf, wordcat %in% c('NOUNI'))
showWordOutError("coffee,tea,wine,beer,water,cake",c("Condition","measure"),romNotFinalN)
romNotFinalN$vromNot=NULL
romNotFinalN$Condition = str_replace(romNotFinalN$Condition," +","")
romNotFinalNtest= subset(romNotFinalN, Condition %in% c("TEST-UNPRED","TEST-PRED"))

print(head(romNotFinalNtest[romNotFinalNtest$measure=="target",c("word","wordcat","Condition","Example","tick")])) # check

# check that layers are the right size

showWordOutError("coffee,tea,wine,beer,water,cake",c("Condition","measure"),romNotFinalNtest)
```

```{r,fig.height=4,fig.width=12}
romNotrawpostverbnotargout.df=removeWordsDrawERP(romNotFinalNtest,"value","Condition","measure","variable",showFig=TRUE)
```


```{r,fig.height=3,fig.width=6}
interactionText="NO TEXT"
modellist2 = list()

romNotinput  = subset(romNotrawpostverbnotargout.df,measure == mainMeasure & layer %in% c("word",p600layer) )
romNotinput$Prime = factor(romNotinput$Condition,labels=c("Predictable","Unpredictable"))

rominput$exp = "repetition"
romNotinput$exp = "norepetition"
rominput2= rbind(rominput,romNotinput) 
aggregate(abssum ~ Condition + exp + layer, rominput2,mean)

rominput4= subset(rominput2,!(exp == "norepetition" & Condition == "TEST-PRED"))
xtabs(~ Condition + exp, rominput4)

rominput4$Condition2=as.character(rominput4$Condition)
rominput4$Condition2[rominput4$exp == "norepetition"]="Not Previously Seen"
rominput4$Condition2 = factor(rominput4$Condition2,labels=c("Not Previously Seen","Previously Predictable","Previously Unpredictable"))
rominput4$cp6layer = ifelse(rominput4$layer==p600layer,0.5,-0.5)

romexamdf = subset(rommerdf,measure == mainMeasure  & layer == "word" & tick == 1,c(1:12))
exampleTable = romexamdf[c(1,3,4),c("Condition","Example")]
exampleTable$Condition = factor(exampleTable$Condition,labels =c("Predictable Prime","Target","Unpredictable Prime"))
romNotexamdf = subset(rommerNotdf,measure == mainMeasure  & layer == "word" & tick == 1,c(1:12))
exampleTable2 = romNotexamdf[c(1,3,4),c("Condition","Example")]
exampleTable2$Condition = factor(exampleTable$Condition,labels =c("Predictable Prime","Target","Unpredictable Prime"))

exampleTable3 = rbind(exampleTable,exampleTable2)
exampleTable3 = exampleTable3[c(1,2,5,6),]
exampleTable3$Condition = c("Previously Predictable","Previously Unpredictable","Not Previously Seen","Critical Target")
exampleTable3[,c(2,1)]
tabletext3 = kable(exampleTable3[,c(2,1)],format="latex",booktab=T,row.names=FALSE)
print(exampleTable3)

randomeff = paste(" + (1 +layer |sub)") 
rominput4$seen =ifelse(rominput4$Condition2=="Not Previously Seen",1,-0.5)
rominput4$pred = 0
rominput4$pred[rominput4$Condition2=="Previously Predictable"]=0.5
rominput4$pred[rominput4$Condition2=="Previously Unpredictable"]=-0.5
contrasts(rominput4$Condition2)<-contr.helmert(3)[c(3,2,1),]

if (noslopes){ randomeff = " + (1 | sub)"}
formu = as.formula(paste(dependMeasure,"~ seen*cp6layer +  pred*cp6layer",randomeff))
omnimodel = lmer(formu, rominput4,control=lmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=50000)))
print(summary(omnimodel))
modellist2 = modelComparison(omnimodel) # create anova table
  # this model is for posthocs

rominput4word = subset(rominput4,layer=="word")
randomeff2 = paste(" + (1  |sub)") 
formu = as.formula(paste(dependMeasure,"~ pred + seen",randomeff2))
omnimodelw = lmer(formu, rominput4word ,control=lmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=50000)))
print(summary(omnimodelw))
modellist3w = modelComparison(omnimodelw) # create anova table

rominput4hid = subset(rominput4,layer=="hidden")
omnimodelh = lmer(formu, rominput4hid,control=lmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=50000)))
print(summary(omnimodelh))
modellist3h = modelComparison(omnimodelh) # create anova table

rominput4$Prime = rominput4$Condition2
  p = drawERP(rominput4,dependMeasure, "Prime", span=1, timeline.y=2)
  p
if (!noslopes){ # when doing final version, change noslopes to FALSE
    myggsave("img/rommers2.png",width=figwidth,height=figheight)
}
```

CUT AND PASTE INTO LATEX DOC
click in box and use right arrow to see whole text

```latex

This is an example of the stimuli used in the model.

```{r,echo=FALSE,results="asis",warning=FALSE,message=FALSE}
#print(paste(tabletext,sep="",collapse="\n"))
cat(paste(tabletext3))

cat(paste("\nThe maximal model for the data had random slopes",randomeff))

cat(paste(printMixedModelResults(modellist2),collapse="\n"))

cat(paste(printMixedModelResults(modellist3w),collapse="\n"))

cat(paste(printMixedModelResults(modellist3h),collapse="\n"))

```
```

## Overall accuracy results

```{r}
test = read.csv("testdata.csv")
testsum = aggregate(cbind(corr,total) ~ epoch, test, sum)
testsum=rbind(testsum,data.frame(epoch=0,corr=0,total=200))
testsum$perc = 100* testsum$corr/testsum$total
p1=ggplot(testsum,aes(x=epoch,y=perc))+geom_line()+ylim(0,100) 
  p1 = p1 + scale_colour_brewer( palette="Set1")
  p1 = p1 + theme_bw() + xlab("Number of patterns trained") 
p1
paste("@@Test Accuracy ",tail(aggregate(perc ~ epoch, test, mean),1))
```

## Example data for introduction
- These figures below are made up data that help to explain the model
- Word Level: The children went out to ...

```{r, echo=FALSE}
n400df=data.frame(cond=rep(c("Expected","Unexpected"),each=6),Context = rep(c("Strong","Weak"),each=3))
n400df$Lexical = c("look","move","play")
n400df$Predicted = c(0.1,0.1,0.5, 0.1,0.3,0.3)
#n400df$Predicted = c(0.2,0.2,0.6, 0.2,0.4,0.4)
#df$Predicted = c(0.2,0.4,0.6, 0.1,0.3,0.3)
n400df$Target = c(0,0,1, 0,1,0, 1,0,0, 1,0,0)
n400df$Error = n400df$Predicted - n400df$Target
n400df$absError = abs(n400df$Error)
n400df2 = aggregate(absError ~ cond + Context,n400df,sum)
names(n400df2)[3]<-"value"
n400df2$variable="Sum Abs. Error"
n400df2$Lexical = "move"
print(n400df2)

dfall=melt(n400df,id.vars=c(1:3))
dfall=dfall[dfall$variable!="absError",]
#dfall$LexCont = paste(dfall$Context,dfall$Lexical)
dfall$Shape = dfall$Lexical
dfall$endlen = 0.2
dfall$linepos = as.numeric(as.factor(dfall$Lexical))
#dfall$LexCont = factor(dfall$LexCont,levels=c("Weak look","Weak move","Weak play","Strong look","Strong move","Strong play"))
#n400df2$LexCont=paste(n400df2$Context,"move")

n400df2$Shape = "SUM"
n400df2$endlen = 1
n400df2$linepos = 2
dfall = rbind(dfall,n400df2)

scaleFUN <- function(x) sprintf("%.1f", x)

equal_breaks <- function(n = 3, s = 0.05, ...){
  function(x){
    # rescaling
#    print(paste("x ",x[2]))
    d <- s * diff(range(x)) / (1+2*s)
    xx = seq(min(x)+d, max(x)-d, length=n)
   # xx = round(xx,1)
   # print(xx)
    round(xx,1)
  }
}
# 
# q = ggplot(n400df2,aes(x=cond,y=value,fill=Context)) +geom_bar(stat="identity",position="dodge")
# q=q+coord_flip()
# q = q  +scale_fill_grey() +scale_colour_grey() 
# q = q + theme_bw()+theme(legend.position="bottom")
# q=q + theme(panel.grid.major = element_blank(), 
#                   panel.grid.minor = element_blank(),
#                   panel.background = element_blank(), 
#                   axis.line = element_line(colour = "black"))
# q

extrapoints=head(dfall[dfall$variable=="Predicted",],1)
extrapoints$value=0.6

extra = rbind(extrapoints)
#p6word4=rbind(p6word4,last)


p = ggplot(dfall,aes(x=linepos,y=value)) 
p = p+ geom_point(data=extra,x=NA)

#+geom_point(stat="identity",size=1)
p = p + facet_grid(cond + Context ~ variable ,scales="free",space="free")
p = p +geom_segment(aes(x = linepos-endlen,xend=linepos+endlen, y=value,yend=value),size=0.5)
p = p +geom_segment(aes(x = linepos,xend=linepos, y=0,yend=value),size=0.5)
p=p+coord_flip()
p = p  +scale_fill_grey() +scale_colour_grey() 
p = p + scale_shape_manual(values=c(15,16,17,5),guide=FALSE)
#p = p + scale_y_continuous(labels=scaleFUN)   
p = p + scale_x_continuous(breaks = 0:3,labels=c("", "look","move","play")) 
p = p + scale_y_continuous(breaks=equal_breaks(n=3, s=0.05), 
                     expand = c(0.05, 0))
#+ geom_text(stat="identity",position="dodge")
p= p +ylab("Activation/Error") +xlab("Words")
p = p + geom_hline(yintercept = 0,linetype="dashed",size=0.5)
#p= p + scale_x_discrete(labels=c("move","look","play","move","look","play"))
p = p + theme_bw()+theme(legend.position="bottom")
p=p + theme(panel.grid.major = element_blank(), 
                  panel.grid.minor = element_blank(),
                  panel.background = element_blank(), panel.spacing = unit(0.5, "lines"),
                  axis.line = element_line(colour = "black"))
p
#myggsave("img/n400example.png",width=10,height=4)
myggsave("img/n400example.png",width=9,height=4)
```

- N400 is sensitive to cloze probabilites of words

## Agreement Lexical Level: The spoilt child throws the toys on the floor

```{r, echo=FALSE}
p6word=data.frame(Grammaticality=rep(c("Gram.","Ungram."),each=4))
p6word$Lexical = c("the","a", "-ed","-ss")
#p = c(0.47,0.47,0.03,0.03)
p = c(0.3,0.3,0.1,0.1)
p6word$Predicted = p
p6word$Target = 0 
p6word$Target[p6word$Lexical == "the" & p6word$Grammaticality == "Gram."] = 1
p6word$Target[p6word$Lexical == "-ed" & p6word$Grammaticality == "Ungram."] = 1
p6word$Error = p6word$Predicted - p6word$Target

p6word$absError = abs(p6word$Error)
p6word2 = aggregate(absError ~ Grammaticality,p6word,sum)
names(p6word2)[2]<-"value"
p6word2$variable="Sum Abs. Error"
p6word2$Lexical = "SUM"
print(p6word2)

dfall=melt(p6word,id.vars=c(1:2))
dfall=dfall[dfall$variable!="absError",]
dfall$Lexical=factor(dfall$Lexical,levels=c("-ss","-ed","a","the"))
#dfall$Shape = dfall$Lexical
dfall
dfall$endlen= 0.2
dfall$nu=0
dfall$linepos = as.numeric(as.factor(dfall$Lexical))

#dfall$GramCont = paste(dfall$Grammaticality,dfall$Lexical)
#dfall$LexCont = factor(dfall$LexCont,levels=c("Weak look","Weak move","Weak play","Strong look","Strong move","Strong play"))
p6word2$Lexical="-ed"
#p6word2$Shape = "zz"
p6word2$nu = 0
  #-0.5
p6word2$endlen=2
p6word2$linepos=2.5
dfall = rbind(dfall,p6word2)
dfall$Grammaticality=factor(dfall$Grammaticality,labels=c("Control","Violation"))

nu= rep(c(0),26)
nu[26] = -0.5
#nu[25] = -0.5
nu[13] = -0.5


p = ggplot(dfall,aes(x=Lexical,y=value)) #+geom_point(stat="identity",size=3,position=position_nudge(x = nu, y = 0))
p = p +geom_segment(aes(x = linepos-endlen,xend=linepos+endlen, y=value,yend=value),size=0.5)
p = p + facet_grid(Grammaticality ~ variable,scales="free",space="free")
p = p + geom_segment(aes(x = linepos,xend=linepos, y=0,yend=value),size=0.5)
p=p+coord_flip()
p = p  +scale_fill_grey() +scale_colour_grey() 
p = p + scale_shape_manual(values=c(15,16,17,18,5),guide=FALSE)
p = p + scale_y_continuous(breaks=equal_breaks(n=2, s=0.05), 
                     expand = c(0.05, 0))
p= p +ylab("Activation/Error") +xlab("Words/Morphemes")
p = p + geom_hline(yintercept = 0,linetype="dashed",size=0.5)
p = p + scale_x_continuous(breaks = 0:4,labels=c("","-ss","-ed","a","the")) 
p = p + theme_bw()+theme(legend.position="bottom")
p=p + theme(panel.grid.major = element_blank(), 
                  panel.grid.minor = element_blank(),
                  panel.background = element_blank(), panel.spacing = unit(0.5, "lines"),
                  axis.line = element_line(colour = "black"))
p
myggsave("img/p600example.png",width=9,height=4)
tarerror = subset(p6word,Target == 1)

```

- Syntactic distinctions do not show an N400

## Agreement Syntactic Level: The spoilt child throws the toys on the floor

```{r, echo=FALSE,height=2}

p6word$Weight = c(4,4,-1,-1)
  #round(10*(p6word$Predicted - 0.1))
p6word$NetinputBack = p6word$Weight*p6word$Error
p6word$Weight2 = c(-1,-1,4,4)
  #round(10*(0.31-p6word$Predicted))
p6word$NetinputBack2 = p6word$Weight2*p6word$Error
print(p6word)

p6word$Sequencing = "S1"
p6word2= p6word
p6word2$Sequencing  = "S2"
p6word2$NetinputBack=p6word2$NetinputBack2
p6word3=rbind(p6word,p6word2)
p6word3$NetinputBack2=NULL
p6word3$Weight2=NULL
p6word3$Grammaticality = factor(p6word3$Grammaticality, labels=c("Control", "Violation"))
p6word4 = p6word3[,c("Grammaticality","Sequencing","Lexical","NetinputBack")]
hiddendf = aggregate(cbind(NetinputBack,NetinputBack2) ~ Grammaticality, p6word, sum)
hiddendf$Error = abs(hiddendf$NetinputBack)+abs(hiddendf$NetinputBack2)
p6word4$Type = "Weighted Lexical Error"
p6word4$endlen =  0.2
p6word4$seqpos = as.numeric(as.factor(p6word4$Sequencing))

p6word4$Lexical = factor(p6word4$Lexical,levels=c("-ss","-ed","a","the"))
p6word4$linepos = as.numeric(p6word4$Lexical)+4*(p6word4$seqpos-1)

print(hiddendf)
sumdf = data.frame(Grammaticality=hiddendf$Grammaticality,Sequencing=rep(c("S1","S2"),each=2),Lexical="-ed",NetinputBack=c(as.numeric(hiddendf$NetinputBack),as.numeric(hiddendf$NetinputBack2)),Type="Sequencing Error")
sumdf$Grammaticality = factor(sumdf$Grammaticality, labels=c("Control", "Violation"))
sumdf$seqpos = as.numeric(as.factor(sumdf$Sequencing))

sumdf$linepos=2.5+4*(sumdf$seqpos-1)
sumdf$endlen = 2
p6word4 = rbind(p6word4,sumdf)
p6word4$width=0.9
sumdf2 = data.frame(Grammaticality=rep(hiddendf$Grammaticality),Sequencing=c("S1"),Lexical="a",NetinputBack=rep(as.numeric(hiddendf$Error)),Type="Sum Abs. Error",width=1.0)
sumdf2$Grammaticality = factor(sumdf2$Grammaticality, labels=c("Control", "Violation"))
sumdf2$linepos=4.5
sumdf2$endlen = 4
sumdf2$seqpos=0
p6word4 = rbind(p6word4,sumdf2)
p6word4$Type = factor(p6word4$Type,levels=c("Weighted Lexical Error","Sequencing Error","Sum Abs. Error"))

#p6word4$SeqLex = paste(p6word4$Sequencing,p6word4$Lexical)
#p6word4$SeqLex = factor(p6word4$SeqLex,levels=c("S2 a","S2 the","S2 -ed","S2 -ss","S1 a","S1 the","S1 -ed","S1 -ss"))

nn= length(p6word4$Lexical)
nu= rep(c(0), nn)
#nu[nn/4] = -0.5
#nu[nn/2] = -0.5
#nu[nn/2-1] = -0.5
#nu[nn/2-2] = -0.5
#nu[nn/2-1] = -0.5
#nu[3*nn/4] = -0.5
#u[nn] = -0.5
#nu[nn-1] = -0.5
#nu[nn-2] = -0.5

extrapoints=head(p6word4[p6word4$Type=="Sum Abs. Error",],1)
extrapoints$NetinputBack=8
extrapoints2=head(p6word4[p6word4$Type=="Sequencing Error",],1)
extrapoints2$NetinputBack=4
extrapoints3=head(p6word4[p6word4$Type=="Weighted Lexical Error",],1)
extrapoints3$NetinputBack=-4
extrapoints4=extrapoints3
extrapoints4$NetinputBack=2
extra = rbind(extrapoints,extrapoints2,extrapoints3,extrapoints4)
#p6word4=rbind(p6word4,last)

p6word4$Sequencing = factor(p6word4$Sequencing,levels=c("S1","S2"))
p = ggplot(p6word4,aes(x=linepos,y=NetinputBack))
p = p+ geom_point(data=extra,x=NA)
p = p +geom_segment(aes(x = linepos-endlen,xend=linepos+endlen, y=NetinputBack,yend=NetinputBack,color=Sequencing),size=0.5)
#+geom_point(stat="identity",size=3,position=position_nudge(x = nu, y = 0))
p = p + facet_grid(Grammaticality ~ Type,scales="free",space="free")
p = p + geom_segment(aes(x = linepos,xend=linepos, y=0,yend=NetinputBack,color=Sequencing),size=0.5)
#position=position_nudge(x = nu, y = 0)
p=p+coord_flip()
p = p  +scale_fill_grey() +scale_colour_grey() 
p = p + scale_shape_manual(values=c(15,16,17,18,5))
    
#+ geom_text(stat="identity",position="dodge")
p= p +ylab("Error") +xlab("Words/Morphemes")
p = p + geom_hline(yintercept = 0,linetype="dashed",size=0.5)
p = p + scale_x_continuous(breaks = 0:8,labels=c("", "-ss","-ed","a","the", "-ss","-ed","a","the")) 

#p= p + scale_x_discrete(labels=c("a","the","-ed","-ss","a","the","-ed","-ss"))
#p = p + scale_y_continuous(breaks=equal_breaks(n=4, s=0.05), 
#                     expand = c(0.05, 0))

p = p + theme_bw()+theme(legend.position="bottom")
p=p + theme(panel.grid.major = element_blank(), 
                  panel.grid.minor = element_blank(),
                  panel.background = element_blank(),  panel.spacing = unit(0.5, "lines"),
                  axis.line = element_line(colour = "black"))
justse = subset(p6word4,Sequencing == "S1" & Type == "Sequencing Error")
justse$txt[1]="Positive and\nnegative error\ncancel out"
justse$txt[2]="Positive error\naccumulates"
justse$NetinputBack = c(2.2,-1.8)
justse$linepos[1]=2.8
p = p + geom_text(data=justse,aes(x=linepos,y=NetinputBack,label = txt),size=3)
p
myggsave("img/weightederror.png",width=8,height=6)

```

## Agreement Wave ERP: The spoilt child throws the toys on the floor

```{r, echo=FALSE,height=3,width=6}
hiddendf$NetinputBack = NULL
hiddendf$NetinputBack2 = NULL
worddf = aggregate(absError ~ Grammaticality, p6word, sum) # n4
names(worddf)[2] <- "Error"
p6df = rbind(hiddendf,worddf)
p6df$layer = c("Sequencing","Sequencing","Lexical","Lexical")
p6df$layer = factor(p6df$layer, levels=c("Lexical", "Sequencing"))
p6df$depth = -3 + 2+2*as.numeric(p6df$layer)
p6df$Grammaticality = factor(p6df$Grammaticality, labels=c("Control", "Violation"))

#mapping = aes_string(x="depth", y="Error", colour = "Grammaticality",linetype="Grammaticality")
p = drawERP(p6df,"Error", "Grammaticality",timeline.y=7,span=0.9, layerlabels=c("Stimulus", "Lexical", "Sequencing"))
p=p + theme(panel.grid.major = element_blank(), 
                  panel.grid.minor = element_blank(),
                  panel.background = element_blank(), 
                  axis.line = element_line(colour = "black"))

#p = p +theme_bw()+theme(legend.position="bottom")
p
myggsave("img/p600wave.png",width=6,height=3)

```

## Draw Sequencing-Hidden Network

```{r, echo=FALSE,height=2}
p6word
p6wordlong = p6word
p6wordlong$Grammaticality=factor(p6wordlong$Grammaticality,labels=c("S1","S2"))
names(p6wordlong)[1]<-"Sequencing"
p6wordlong$Weight[5:8]=p6wordlong$Weight2[1:4]
#p6wordlong$NetinputBack[5:8]=p6wordlong$NetinputBack2[1:4]
p6wordlong = p6wordlong[,c("Sequencing","Lexical","Weight")]
p6wordlong$Sequencing = as.character(p6wordlong$Sequencing)

unitsdf = data.frame(unit=unique(c(p6wordlong$Sequencing,p6wordlong$Lexical)))
unitsdf$xx = c(1.5,3.5,1:4)
unitsdf$yy = c(1,1,3,3,3,3)

p6wordlong2 = merge(p6wordlong,unitsdf,by.x="Sequencing",by.y="unit")
p6wordlong3 = merge(p6wordlong2,unitsdf,by.x="Lexical",by.y="unit")
p6wordlong3$xx.y = p6wordlong3$xx.y + (p6wordlong3$xx.x-mean(p6wordlong3$xx.x))/30
# pos of label
posprop = 0.2
p6wordlong3$xlab = (1-posprop)*p6wordlong3$xx.y+posprop*p6wordlong3$xx.x
posprop = posprop-0.01
p6wordlong3$ylab = (1-posprop)*p6wordlong3$yy.y+posprop*p6wordlong3$yy.x
p6wordlong3$Weight=factor(p6wordlong3$Weight)
shorten = 0.3

p = ggplot() 
p = p + geom_tile(aes(x=xx, y=yy, label=unit),unitsdf, colour="black",fill=NA,size=1,width=0.6,height=0.4)
p = p +geom_text(aes(x=xx, y=yy, label=unit),unitsdf)
p = p + theme_bw()
p = p + geom_segment(data=p6wordlong3, aes(x=xx.x, xend=xx.y, y=yy.x+shorten, yend=yy.y-shorten,colour=Weight),size=1,arrow=arrow(length = unit(0.2, "cm"),type = "closed"))
#p = p +geom_text(aes(x=xlab, y=ylab, label=Weight),p6wordlong3)
p = p + scale_colour_grey(start = 0.8, end = 0.2)
p = p + theme(axis.line=element_blank(),axis.text.x=element_blank(),
          axis.text.y=element_blank(),axis.ticks=element_blank(),
          axis.title.x=element_blank(),
          axis.title.y=element_blank(),
          #legend.position="none",
          panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
          panel.grid.minor=element_blank(),plot.background=element_blank())

p = p + annotate(geom="text",x=0.2,y=3.5,label="Lexical Layer",hjust = 0)
p = p + annotate(geom="text",x=0.2,y=1.5,label="Sequencing Layer",hjust = 0)
p
myggsave("img/p6backnet.png",width=6,height=2)

```



## box diagram

```{r, echo=FALSE,height=2}
unitsdf = data.frame(xx=c(1,2,3,4,1,2,3,4,1,2,3,4))
unitsdf$xx = unitsdf$xx * 2
unitsdf$yy = rep(c(1,1.5,2),each=4)
unitsdf$label = c("Heard\nInput","Error","Lexical\nLayer","Sequencing\nLayer")

segdf = data.frame(yy=c(2,2,2,1.5,1),xx2=c(3.1,4.9,6.9,5.1,7.1),xx = c(2.8,5.2,7.2,4.8,6.8),col=c("B","A","A","B","B"))

p = ggplot() 
p = p + geom_tile(aes(x=xx, y=yy, label=label),unitsdf,colour="black",fill=NA,size=1,width=1.6,height=0.3)
p = p +geom_text(aes(x=xx, y=yy, label=label),unitsdf)
p = p + theme_bw()
p = p + geom_segment(data=segdf, aes(x=xx, xend=xx2, y=yy, yend=yy, colour=col),size=2,arrow=arrow(length = unit(0.2, "cm"),type = "closed"))
p = p + scale_colour_grey(start = 0.8, end = 0.2)
p = p + theme(axis.line=element_blank(),axis.text.x=element_blank(),
          axis.text.y=element_blank(),axis.ticks=element_blank(),
          axis.title.x=element_blank(),
          axis.title.y=element_blank(),
          legend.position="none",
          panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
          panel.grid.minor=element_blank(),plot.background=element_blank())
p = p + annotate(geom="text",x=2,y=2.25,label="at 0 ms after stimulus onset",hjust = 0)
p = p + annotate(geom="text",x=5,y=1.75,label="at 400 ms",hjust = 0)
p = p + annotate(geom="text",x=7,y=1.25,label="at 600 ms",hjust = 0)
#p
#myggsave("img/boxmodel.png",width=6,height=3)

```


## Word Level

```{r, echo=FALSE,height=2}

n400df$absError = abs(n400df$Error)
n400df2 = aggregate(absError ~ Context + cond,n400df,sum)
n400df2$layer="Lexical"
n400df3 = n400df2
n400df3$absError=abs(rnorm(length(n400df3$layer),mean=0,sd=0.1))
n400df3$layer = "Sequencing"
n400df2=rbind(n400df2,n400df3)
n400df2$layer=factor(n400df2$layer)
n400df2$depth = -3 + 2+2*as.numeric(n400df2$layer)

n400df2$absError[n400df2$Context == "Weak" & n400df2$cond == "Unexpected"]=n400df2$absError[n400df2$Context == "Weak" & n400df2$cond == "Unexpected"]+0.05

longnoraw2 = n400df2
longnoraw2$Condition = longnoraw2$cond
# mapping = aes_string(x="depth", y="absError", colour = "Context",linetype="Condition")
p = drawERP(longnoraw2,"absError","Condition","Context", timeline.y=1.8,span=0.9,layerlabels=c("Stimulus", "Lexical", "Sequencing"))
p=p +theme_bw()+theme(legend.position="bottom")
p=p + theme(panel.grid.major = element_blank(), 
                  panel.grid.minor = element_blank(),
                  panel.background = element_blank(), 
                  axis.line = element_line(colour = "black"))
p
myggsave("img/n400wave.png",width=6,height=3)

```



## Draw Network

```{r, echo=FALSE,height=2}
df <- data.frame()
df = rbind(df,data.frame(x=2,y=0,name = "PrevWord"))
df = rbind(df,data.frame(x=3,y=0,name = "PrevWordHistory"))
df = rbind(df,data.frame(x=1,y=3,name = "EventSemantics"))
df = rbind(df,data.frame(x=3,y=2,name = "Context"))
df = rbind(df,data.frame(x=2.3,y=3,name = "Hidden"))
df = rbind(df,data.frame(x=3,y=4.5,name = "Compress"))
df = rbind(df,data.frame(x=2,y=6,name = "NextWord"))

df = rbind(df,data.frame(x=1,y=4,name = "Role"))
df = rbind(df,data.frame(x=1,y=5,name = "Concept"))
df = rbind(df,data.frame(x=1,y=2,name = "CRole"))
df = rbind(df,data.frame(x=1,y=1,name = "CConcept"))
df = rbind(df,data.frame(x=1.8,y=2,name = "CRoleHistory"))
#df$width = str_length(df$name)

hw = 0.35
hh = 0.25
arrowdf = data.frame()
arrowdf = rbind(arrowdf,data.frame(from = "PrevWord",to="Hidden",fx=0.1,fy=hh, tx=0,ty=-hh))
arrowdf = rbind(arrowdf,data.frame(from = "PrevWordHistory",to="Hidden",fx=-.2,fy=hh, tx=0.1,ty=-hh))
arrowdf = rbind(arrowdf,data.frame(from = "Concept",to="NextWord",fx=hw,fy=hh, tx=-hw,ty=-hh))
arrowdf = rbind(arrowdf,data.frame(from = "Compress",to="NextWord",fx=0,fy=hh, tx=hw,ty=-hh))
arrowdf = rbind(arrowdf,data.frame(from = "Hidden",to="Role",fx=-hw,fy=hh, tx=hw,ty=-hh))
arrowdf = rbind(arrowdf,data.frame(from = "Hidden",to="Compress",fx=0,fy=hh, tx=-hw,ty=-hh))
arrowdf = rbind(arrowdf,data.frame(from = "Context",to="Hidden",fx=0,fy=hh, tx=hw,ty=-hh))
arrowdf = rbind(arrowdf,data.frame(from = "Hidden",to="Context",fx=hw,fy=0, tx=0.2,ty=hh+0.05))
arrowdf = rbind(arrowdf,data.frame(from = "EventSemantics",to="Hidden", fx=hw,fy=0, tx=-hw,ty=0))
arrowdf = rbind(arrowdf,data.frame(from = "CRole",to="Hidden",fx=0,fy=hh, tx=-hw,ty=-hh))
arrowdf = rbind(arrowdf,data.frame(from = "CRoleHistory",to="Hidden",fx=0.2,fy=hh, tx=-0.2,ty=-hh))
arrowdf = rbind(arrowdf,data.frame(from = "PrevWord",to="CConcept",fx=-hw,fy=hh, tx=hw,ty=-hh))
arrowdf = rbind(arrowdf,data.frame(from = "CRole",to="CRoleHistory",fx=hw,fy=0, tx=-hw,ty=0))

arrowdf = merge(arrowdf,df,all.x=T,by.x="from",by.y="name")
la = length(arrowdf)
names(arrowdf)[(la-1):la]<-c("fromx","fromy")
arrowdf = merge(arrowdf,df,all.x=T,by.x="to",by.y="name")
la = length(arrowdf)
names(arrowdf)[(la-1):la]<-c("tox","toy")
arrowdf$name = ""
arrowdf$type = "basic"
arrowdf$type[arrowdf$from=="Hidden"& arrowdf$to=="Context"] = "copy"
arrowdf$type[arrowdf$from=="CRole" & arrowdf$to=="CRoleHistory"] = "copy"

marrowdf = data.frame()
marrowdf = rbind(marrowdf,data.frame(from = "CConcept",to="CRole",fx=0,fy=hh, tx=0,ty=-hh))
marrowdf = rbind(marrowdf,data.frame(from = "Role",to="Concept",fx=0,fy=hh, tx=0,ty=-hh))
marrowdf = merge(marrowdf,df,all.x=T,by.x="from",by.y="name")
la = length(marrowdf)
names(marrowdf)[(la-1):la]<-c("fromx","fromy")
marrowdf = merge(marrowdf,df,all.x=T,by.x="to",by.y="name")
la = length(marrowdf)
names(marrowdf)[(la-1):la]<-c("tox","toy")
marrowdf$name = ""
marrowdf$type = "basic"

p = ggplot(df, aes(x=x, y=y, label=name)) 
p = p + geom_segment(data=arrowdf, aes(x=fromx+fx, xend=tox+tx, y=fromy+fy, yend=toy+ty,linetype=type),size=1,arrow=arrow(length = unit(0.2, "cm"),type = "closed"))
p = p + geom_segment(data=marrowdf, aes(x=fromx+fx, xend=tox+tx, y=fromy+fy, yend=toy+ty,linetype=type),size=3)
p = p + geom_tile(colour="black",fill=NA,size=1,width=hw*2,height=hh*2)+geom_text()
p = p + annotate(geom="text",x=1,y=7,label="Message System")
p = p + annotate(geom="text",x=2.5,y=7,label="Sequencing System")
p = p + theme(axis.line=element_blank(),axis.text.x=element_blank(),
          axis.text.y=element_blank(),axis.ticks=element_blank(),
          axis.title.x=element_blank(),
          axis.title.y=element_blank(),legend.position="none",
          panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
          panel.grid.minor=element_blank(),plot.background=element_blank())

p=p + annotate(geom="segment",x=0.5,xend=0.5,y=0.5,yend=6,colour="gray80",size=2,arrow = arrow(length = unit(0.3, "cm")))
p= p + annotate(geom="segment",x=3.5,xend=3.5,y=5.3,yend=0,colour="gray80",size=2,arrow = arrow(length = unit(0.3, "cm")))
p=p + annotate(geom="text",x=0.5,y=0,label="Forward pass\ngenerates prediction")
p = p + annotate(geom="text",x=3.5,y=6,label="Error\npropagates\nbackwards")
p + xlim(0.2,3.6)
myggsave("img/network.png",width=7,height=6)

```


## Draw Brain1

```{r, echo=FALSE,height=8,width=8}
d=3
#brain <- data.frame(x = 2*rep(1:d,each=d),y = 2*rep(1:d,d),act = abs(rnorm(d*d)))
#sam = sample(length(brain$x),d*d/2)
#brain$x[sam]= brain$x[sam] + 13
#lexbrain <- data.frame(x = c(1,3,2),y = c(1,3,6),word=c("sugar","toy","dog"),act=c(0.9,0.1,0.1),error=c(0.1,0.1,0.9))
#synbrain <- data.frame(x = c(8,9,9),y = c(1,3,6),word=c("","",""),act=c(0.5,0.3,0.6),error=c(0.4,0.5,0.3))
#brain = rbind(lexbrain,synbrain)
lexlay=3.5
synlay=7
lexbrain <- data.frame(x = lexlay,y = c(2,4),word=c("sugar","dog"),act=c(0.9,0.1),error=c(0.9,0.9))
synbrain <- data.frame(x = synlay,y = c(2,4),word=c("",""),act=c(0.5,0.3),error=c(0.1,0.2))
brain = rbind(lexbrain,synbrain)

eegwaves = data.frame(x=1:70,y=rnorm(70),act=NA,word=NA,error=NA)
eegwaves$y = eegwaves$y*0.1
eegwaves$y2 = rnorm(70)*0.1
eegwaves$y3 = rnorm(70)*0.1
reg = eegwaves$x > 25 & eegwaves$x < 35
prev = (4-abs(eegwaves$x[reg]-mean(eegwaves$x[reg])))*0.15
eegwaves$y[reg] = eegwaves$y[reg] - prev
reg = eegwaves$x > 23 & eegwaves$x < 36
prev = (4-abs(eegwaves$x[reg]-mean(eegwaves$x[reg])))*0.15
eegwaves$y2[reg] = eegwaves$y2[reg] - prev
reg = eegwaves$x > 24 & eegwaves$x < 34
prev = (4-abs(eegwaves$x[reg]-mean(eegwaves$x[reg])))*0.15
eegwaves$y3[reg] = eegwaves$y3[reg] - prev
#eegwaves$y2[eegwaves$x > 30 & eegwaves$x < 45] = eegwaves$y2[eegwaves$x > 30 & eegwaves$x < 45] - 0.5
#eegwaves$y3[eegwaves$x > 35 & eegwaves$x < 45] = eegwaves$y3[eegwaves$x > 35 & eegwaves$x < 45] - 0.6
eegwaves$x = eegwaves$x*0.12
eegwaves$erp = (eegwaves$y+eegwaves$y2+eegwaves$y3)/3
eegwaves$error = 0.2
            
p =ggplot(brain)
p=p+geom_text(aes(x=x,y=y,colour=act,label=word),nudge_y=0.5,size=4,colour="black")
p = p +geom_tile(aes(x=x,y=y+1,fill=error),width=0.5,height=0.5,colour="black")
p = p +geom_point(aes(x=x,y=y,fill=act,colour=act),size=7,colour="grey50")
#p = p +geom_text(aes(x=x,y=y+1.25,fill=error),size=12,colour="grey",label="-")
p = p +geom_point(aes(x=x,y=y,fill=act,colour=act),size=6)
#p = p + annotate("rect",xmin=-1,xmax = 9, ymin=-2, ymax=15,width=4,fill=NA,colour="blue")
p = p + annotate("text",x = synlay+0.7, y = 7, label = "EEG",size=4,hjust=0)
p = p +geom_line(mapping=aes(x=x,y=y+7.5),data=eegwaves,colour="grey50")
p = p +geom_line(mapping=aes(x=x,y=y2+8),data=eegwaves,colour="grey50")
p = p +geom_line(mapping=aes(x=x,y=y3+8.5),data=eegwaves,colour="grey50")
p = p + annotate("text",x = synlay+0.7, y = 9.9, label = "ERP",size=4,hjust=0)

p = p + geom_ribbon(aes(x=x,ymin=erp+9.5-error, ymax=erp+9.5+error), alpha = 0.3,data=eegwaves)
p = p +geom_line(mapping=aes(x=x,y=erp+9.5),data=eegwaves,colour="black")

p = p + annotate("text",x = lexlay, y = 5.1,size=12,colour="grey",label="-")
p = p + annotate("text",x = lexlay, y = 3.1,size=12,colour="grey",label="-")
p = p + annotate("text",x = 0.1, y = 6.8, label = "0ms",size=3,hjust=0)
p = p + annotate("text",x = lexlay-0.2, y = 6.8, label = "400ms",size=3,hjust=0)
p = p + annotate("text",x = synlay-0.2, y = 6.8, label = "600ms",size=3,hjust=0)

p=p + annotate(geom="segment",x=lexlay,xend=lexlay,y=5.5,yend=6.5,colour="gray50",arrow = arrow(length = unit(0.3, "cm")))
p=p + annotate(geom="segment",x=synlay,xend=synlay,y=5.5,yend=6.5,colour="gray50",arrow = arrow(length = unit(0.3, "cm")))
p = p + annotate("text",x = lexlay-0.3, y = 6, label = "sum()",size=5,hjust=0.5, parse=T)
p = p + annotate("text",x = synlay-0.3, y = 6, label = "sum()",size=5,hjust=0.5, parse=T)

#brain
p = p + annotate("text",x = lexlay, y = 1, label = "Lexical\nLayer")
p = p + annotate("text",x = 7, y = 1, label = "Sequencing\nLayer")
p=p + annotate(geom="segment",x=lexlay+1,xend=synlay-1,y=5,yend=5,colour="gray80",size=2,arrow = arrow(length = unit(0.2, "cm")))
p = p + annotate("text",x = (lexlay+synlay)/2, y = 4, label = "Error\nPropagation")
p=p + annotate(geom="segment",x=synlay-1,xend=lexlay+1,y=2,yend=2,colour="gray80",size=2,arrow = arrow(length = unit(0.2, "cm")))
p = p + annotate("text",x = (lexlay+synlay)/2, y = 1, label = "Prediction")
p=p + annotate(geom="segment",x=1,xend=lexlay-1,y=5,yend=5,colour="gray80",size=2,arrow = arrow(length = unit(0.2, "cm")))
p = p + annotate("text",x = 0.3, y = 5.4, label = "I take coffee \nwith cream and \ndog",hjust=0)
  
#               \"I drink coffee \nwith cream and atop(bold(dog))\"',parse=TRUE)
p = p + annotate("text",x = lexlay/2, y = 4, label = "Heard\nInput")
#p = p + annotate("text",x = 0.3, y = 5, label = "\"dog\"")

p = p + annotate(geom="segment",x=0,xend=0,y=2,yend=10,linetype="dotted",colour="gray50") # 0 axis

p=p + annotate(geom="segment",x=lexlay,xend=lexlay,y=8,yend=8.7,colour="gray50",arrow = arrow(length = unit(0.3, "cm")))
p = p + annotate("text",x = -0.1, y = 9.9, label = "+",size=5,hjust=0.5)
p = p + annotate("text",x = -0.1, y = 9.2, label = "-",size=5,hjust=0.5)

p = p + scale_fill_gradient(low = "white", high = "black")
p = p + scale_colour_gradient(low = "white", high = "black")
p = p + theme(axis.line=element_blank(),axis.text.x=element_blank(),
          axis.text.y=element_blank(),axis.ticks=element_blank(),
          axis.title.x=element_blank(),
          axis.title.y=element_blank(),legend.position="none",
          panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
          panel.grid.minor=element_blank(),plot.background=element_blank())
p
myggsave("img/brain1.png",width=6,height=6)

```

## Draw Brain2

```{r, echo=FALSE,height=8,width=8}
lexlay=3.5
synlay=7
d = 3
nsize = 0.3
lexbrain <- data.frame(layer="lexical",x = lexlay-nsize*d/2+nsize*rep(1:d,each=d),y = nsize*rep(1:d,d),error = abs(rnorm(d*d))/3)
synbrain <- data.frame(layer="syntax",x = synlay-nsize*d/2+nsize*rep(1:d,each=d),y = nsize*rep(1:d,d),error = 0.4+abs(rnorm(d*d)))
brain = rbind(lexbrain,synbrain)

sd=1.4
eegwaves = data.frame(x=1:70,y=rnorm(70,mean=0,sd=1.4))
eegwaves$y = eegwaves$y*0.1
reg = eegwaves$x > 55 & eegwaves$x < 65
prev = (4-abs(eegwaves$x[reg]-mean(eegwaves$x[reg])))*0.15
eegwaves$y[reg] = eegwaves$y[reg] + prev
eegwaves$x = eegwaves$x*0.12
eegwaves$sourceerp = eegwaves$y
eegwaves$sourceerp2 = rnorm(70,mean=0,sd=1.4)*0.1

err = 0.1
scalperr=0.22



p =ggplot(brain)
p = p +geom_tile(aes(x=x,y=y+1,fill=error),colour="black")
p = p +geom_text(aes(x=x,y=y+1,label="-"),subset(brain,layer=="lexical"),size=4,colour="black")
p = p + annotate(geom="segment",x=0,xend=0,y=2,yend=7,linetype="dotted",colour="gray50") # 0 axis
# source erps
p = p +geom_line(mapping=aes(x=x,y=sourceerp+4),data=eegwaves,colour="black")
p = p + geom_ribbon(aes(x=x,ymin=4+sourceerp-err, ymax=4+sourceerp+err), data=eegwaves,alpha=0.2)
p = p +geom_line(mapping=aes(x=x,y=sourceerp2+4),data=eegwaves,colour="black",linetype="dashed")
p = p + geom_ribbon(aes(x=x,ymin=4+sourceerp2-err, ymax=4+sourceerp2+err), data=eegwaves,alpha=0.2)
# scalp erps
p = p +geom_line(mapping=aes(x=x,y=sourceerp+6),data=eegwaves,colour="black")
p = p + geom_ribbon(aes(x=x,ymin=6+sourceerp-scalperr, ymax=6+sourceerp+scalperr), data=eegwaves,alpha=0.2)
p = p +geom_line(mapping=aes(x=x,y=sourceerp2+6),data=eegwaves,colour="black",linetype="dashed")
p = p + geom_ribbon(aes(x=x,ymin=6+sourceerp2-scalperr, ymax=6+sourceerp2+scalperr), data=eegwaves,alpha=0.2)

p = p + annotate("rect",xmin=-0.3,xmax = 8.5, ymin=0, ymax=5,size=4,fill=NA,colour="grey")

p = p + annotate("text",x = lexlay*0.8, y = 1, label = "Error\nComputed",size=3,hjust=0.5)
p = p + annotate("text",x = (lexlay+synlay)*0.55, y = 1, label = "Back-propagation\nof Error",size=3,hjust=0.5)
p = p + annotate("text",x = synlay-0.9, y = 1+2*nsize, label = "sum()",size=3,hjust=0.5, parse=T)
p=p + annotate(geom="segment",x=lexlay+nsize*2,xend=synlay-1,y=1+nsize,yend=1+2*nsize,colour="gray50",arrow = arrow(length = unit(0.3, "cm")))
p=p + annotate(geom="segment",x=lexlay+nsize*2,xend=synlay-1,y=1+2*nsize,yend=1+2*nsize,colour="gray50",arrow = arrow(length = unit(0.3, "cm")))
p=p + annotate(geom="segment",x=lexlay+nsize*2,xend=synlay-1,y=1+3*nsize,yend=1+2*nsize,colour="gray50",arrow = arrow(length = unit(0.3, "cm")))
#p=p + annotate(geom="segment",x=(lexlay+synlay)*0.25,xend=(lexlay+synlay)*0.75,y=1,yend=1,colour="gray50",arrow = arrow(length = unit(0.3, "cm")))
p=p + annotate(geom="segment",x=synlay-0.8,xend=synlay-nsize-0.05,y=1+2*nsize,yend=1+2*nsize,colour="gray50",size=1.5,arrow = arrow(length = unit(0.3, "cm")))
p = p + annotate("text",x = 0.1, y = 3.5, label = "0ms",size=3,hjust=0)
p = p + annotate("text",x = lexlay+0.3, y = 3.5, label = "400ms",size=3,hjust=0)
p = p + annotate("text",x = synlay+0.3, y = 3.5, label = "600ms",size=3,hjust=0)
p = p + annotate("text",x = lexlay+0.19, y = 0.7, label = "Lexical\nLayer")
p = p + annotate("text",x = synlay+0.19, y = 0.7, label = "Sequencing\nLayer")

p = p + annotate("text",x = 1.5, y = 3.4, label = "Violation",size=3,hjust=0)
p = p + annotate("text",x = 1.5, y = 3.0, label = "Control",size=3,hjust=0)
p = p + annotate("segment",x = 1, xend=1.4, y = 3.0, yend=3.0, linetype="dashed")
p = p + annotate("segment",x = 1, xend=1.4, y = 3.4,yend = 3.4)

p=p + annotate(geom="segment",x=0.8,xend=lexlay-nsize-0.3,y=1+2*nsize,yend=1+2*nsize,colour="gray50",size=1.5,arrow = arrow(length = unit(0.3, "cm")))
p = p + annotate("text",x = 0.4, y = 1.5, label = "Heard\nWord\n(Target)",size=3,hjust=0.5)

p=p + annotate(geom="segment",x=lexlay+nsize/2,xend=lexlay+nsize/2,y=2.2,yend=3.5,colour="gray50",arrow = arrow(length = unit(0.3, "cm")))
p=p + annotate(geom="segment",x=synlay+nsize/2,xend=synlay+nsize/2,y=2.2,yend=3.5,colour="gray50",arrow = arrow(length = unit(0.3, "cm")))
p = p + annotate("text",x = lexlay-0.1, y = 2.7, label = "sum()",size=5,hjust=0.5, parse=T)
p = p + annotate("text",x = synlay-0.1, y = 2.7, label = "sum()",size=5,hjust=0.5, parse=T)
p = p + annotate("text",x = (lexlay+synlay)/2, y = 2.7, label = "ERPs are summed activity \nover many neurons\n(Sum Abs. Error)",size=3,hjust=0.5)

p = p + annotate("text",x = 8, y = 4.8, label = "Skull",size=3,hjust=0)

p = p + annotate("text",x = 0.1, y = 4.5, label = "Source ERP",size=4,hjust=0)
p = p + annotate("text",x = 0.1, y = 6.8, label = "Scalp ERP",size=4,hjust=0)
p=p + annotate(geom="segment",x=5,xend=5,y=4.4,yend=5.5,colour="gray50",arrow = arrow(length = unit(0.3, "cm")))
p = p + annotate("text",x = 4.9, y = 5.3, label = "Noise from other sources combine",size=3,hjust=1)
p = p + annotate("text",x = -0.1, y = 6.3, label = "+",size=5,hjust=0.5)
p = p + annotate("text",x = -0.1, y = 5.5, label = "-",size=5,hjust=0.5)

p = p + scale_fill_gradient(low = "white", high = "black")
p = p + scale_colour_gradient(low = "white", high = "black")
p = p + theme(axis.line=element_blank(),axis.text.x=element_blank(),
          axis.text.y=element_blank(),axis.ticks=element_blank(),
          axis.title.x=element_blank(),
          axis.title.y=element_blank(),legend.position="none",
          panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
          panel.grid.minor=element_blank(),plot.background=element_blank())
p
myggsave("img/brain2.png",width=8,height=6)

```


## Draw Brain3

```{r, echo=FALSE,height=6,width=8}
brain$act=abs(rnorm(length(brain$layer)))
brain$act[brain$layer=="lexical"]=0
brain$act[4]=1
brain$act[16]=5
brain$meaning = abs(rnorm(length(brain$layer)))
brain$meaning[brain$layer=="lexical"]=0
brain$meaning[4]=1

brain$xx=brain$x
brain$xx[brain$layer=="syntax"]=brain$x[brain$layer=="syntax"]-1.7

p =ggplot(brain)
p = p +geom_tile(aes(x=x,y=y+1,fill=error),colour="black")
p = p +geom_text(aes(x=x,y=y+1,label="-"),subset(brain,layer=="lexical"),size=4,colour="black")
p = p +geom_tile(aes(x=xx-2.2,y=y-0.5,fill=act),colour="black")
p = p +geom_tile(aes(x=xx-1,y=y-2,fill=meaning),colour="black")
p = p + annotate(geom="segment",x=0,xend=0,y=0,yend=3.5,linetype="dotted",colour="gray50") # 0 axis
# scalp erps
erppos=3
p = p +geom_line(mapping=aes(x=x,y=sourceerp+erppos),data=eegwaves,colour="black")
p = p +geom_line(mapping=aes(x=x,y=sourceerp2+erppos),data=eegwaves,colour="black",linetype="dashed")

p = p + annotate("text",x = (lexlay+synlay)*0.55, y = 1, label = "Back-propagation\nof Error",size=3,hjust=0.5)
p = p + annotate("text",x = synlay-0.9, y = 1+2*nsize, label = "sum()",size=3,hjust=0.5, parse=T)
p=p + annotate(geom="segment",x=lexlay+nsize*2,xend=synlay-1,y=1+nsize,yend=1+2*nsize,colour="gray50",arrow = arrow(length = unit(0.3, "cm")))
p=p + annotate(geom="segment",x=lexlay+nsize*2,xend=synlay-1,y=1+2*nsize,yend=1+2*nsize,colour="gray50",arrow = arrow(length = unit(0.3, "cm")))
p=p + annotate(geom="segment",x=lexlay+nsize*2,xend=synlay-1,y=1+3*nsize,yend=1+2*nsize,colour="gray50",arrow = arrow(length = unit(0.3, "cm")))
#p=p + annotate(geom="segment",x=(lexlay+synlay)*0.25,xend=(lexlay+synlay)*0.75,y=1,yend=1,colour="gray50",arrow = arrow(length = unit(0.3, "cm")))
p=p + annotate(geom="segment",x=synlay-0.8,xend=synlay-nsize,y=1+2*nsize,yend=1+2*nsize,colour="gray50",arrow = arrow(length = unit(0.3, "cm")))
p = p + annotate("text",x = 0.1, y = 2.4, label = "0ms",size=3,hjust=0)
p = p + annotate("text",x = lexlay+0.3, y = 2.4, label = "400ms",size=3,hjust=0)
p = p + annotate("text",x = synlay+0.3, y = 2.4, label = "600ms",size=3,hjust=0)
p = p + annotate("text",x = lexlay+0.19, y = 0.9, label = "NextWord\nError")
p = p + annotate("text",x = synlay+0.19, y = 0.9, label = "Hidden\nError")
p = p + annotate("text",x = 1.4, y = -0.6, label = "PrevWord\nActivation")
p = p + annotate("text",x = 3.2, y = -0.6, label = "Hidden\nActivation")
p = p + annotate("text",x = 1.2, y = -1.3, label = "Forward Spread\nof Activation",size=3,hjust=0.5)
p = p + annotate("text",x = 2.6, y = -2.1, label = "CConcept\nActivation")
p=p + annotate(geom="segment",x=2.0,xend=2.5,y=-0.4,yend=-0.8,colour="gray50",arrow = arrow(length = unit(0.3, "cm")))
p = p + annotate("text",x = 4.5, y = -2.1, label = "MeaningComp\nActivation")
p=p + annotate(geom="segment",x=3.2,xend=3.9,y=-1.4,yend=-1.4,colour="gray50",arrow = arrow(length = unit(0.3, "cm")))
p=p + annotate(geom="segment",x=3.7,xend=4.4,y=-0.4,yend=-0.9,colour="gray50",arrow = arrow(length = unit(0.3, "cm")))
# legend
p = p + annotate("text",x = 1.5, y = erppos-0.6, label = "Violation",size=3,hjust=0)
p = p + annotate("text",x = 1.5, y = erppos-0.8, label = "Control",size=3,hjust=0)
p = p + annotate("segment",x = 1, xend=1.4, y = erppos-0.6, yend=erppos-0.6)
p = p + annotate("segment",x = 1, xend=1.4, y = erppos-0.8,yend = erppos-0.8, linetype="dashed")

# arrows to erps
p=p + annotate(geom="segment",x=lexlay+nsize/2,xend=lexlay+nsize/2,y=2.1,yend=erppos-0.4,colour="gray50",arrow = arrow(length = unit(0.3, "cm")))
p=p + annotate(geom="segment",x=synlay+nsize/2,xend=synlay+nsize/2,y=2.1,yend=erppos-0.4,colour="gray50",arrow = arrow(length = unit(0.3, "cm")))
p = p + annotate("text",x = lexlay-0.1, y = 2.3, label = "sum()",size=5,hjust=0.5, parse=T)
p = p + annotate("text",x = synlay-0.1, y = 2.3, label = "sum()",size=5,hjust=0.5, parse=T)
p = p + annotate("text",x = (lexlay+synlay)/2, y = 2.2, label = "Sum Abs. Error",size=3,hjust=0.5)

#p = p + annotate("text",x = 0.3, y = 0.1, label = "\"was\"",size=4,hjust=0.5)
p=p + annotate(geom="segment",x=0.6,xend=0.9,y=0.1,yend=0.1,colour="gray50",arrow = arrow(length = unit(0.3, "cm")))
p = p + annotate("text",x = 2.1, y = 1.3, label = "Target\nSignal",size=3,hjust=0.5)
p=p + annotate(geom="segment",x=1.9,xend=3,y=0.8,yend=1.5,colour="gray50",arrow = arrow(length = unit(0.3, "cm")))

p=p + annotate(geom="segment",x=2,xend=2.7,y=0.1,yend=0.1,colour="gray50",arrow = arrow(length = unit(0.3, "cm")))

p = p + annotate("text",x = -0.1, y = 3.5, label = "+",size=5,hjust=0.5)
p = p + annotate("text",x = -0.1, y = 2.5, label = "-",size=5,hjust=0.5)

p = p + annotate("text",x = 0.2, y = 0.5, label = "The judge charged\n(that)\nthe\ndefendant\nwas",hjust=0,size=3)

p = p + annotate("text",x = 5, y = -0.6, label = "Main Clause/Sentence Complement Ambiguity",hjust=0,size=3)
#p = p + annotate("text",x = 7, y = -0.5, label = "",hjust=0.5,size=3)
#p = p + annotate("text", x = 7.67, y = -0.495, label = "was",size=3, fontface =2)

p = p + annotate("text",x = 6.4, y = 3.5, label = "ERPs",hjust=0.5,size=3,fontface =2)
p = p + annotate("text",x = 4.6, y = 0.1, label = "Eye-movements",hjust=0.5,size=3,fontface =2)
p = p + annotate("text",x = 6.2, y = -1.5, label = "Judgements/\nQuestion Answering",hjust=0.5,size=3,fontface =2)
p = p + annotate(geom="curve",x=5,xend=5,y=-1.6,yend=-1.2,curvature=1.5,colour="gray50",arrow = arrow(length = unit(0.3, "cm")))

p = p + scale_fill_gradient(low = "white", high = "black")
p = p + scale_colour_gradient(low = "white", high = "black")
p = p + theme(axis.line=element_blank(),axis.text.x=element_blank(),
          axis.text.y=element_blank(),axis.ticks=element_blank(),
          axis.title.x=element_blank(),
          axis.title.y=element_blank(),legend.position="none",
          panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
          panel.grid.minor=element_blank(),plot.background=element_blank())
p
myggsave("img/brain3.png",width=8,height=6)

```